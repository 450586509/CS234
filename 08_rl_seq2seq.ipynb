{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_rl_seq2seq.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/450586509/reinforcement-learning-practice/blob/master/08_rl_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDydjcUQyNI5",
        "colab_type": "text"
      },
      "source": [
        "#### 任务 \n",
        "Hebrew->English machine translation for words and short phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVRYmV1dyEMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If True, only translates phrases shorter than 20 characters (way easier).\n",
        "EASY_MODE = True\n",
        "# Useful for initial coding.\n",
        "# If false, works with all phrases (please switch to this mode for homework assignment)\n",
        "\n",
        "MODE = \"he-to-en\"  # way we translate. Either \"he-to-en\" or \"en-to-he\"\n",
        "# maximal length of _generated_ output, does not affect training\n",
        "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20\n",
        "REPORT_FREQ = 100  # how often to evaluate validation score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5WR2Gde6tfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cHHaS1Qz-no",
        "colab_type": "text"
      },
      "source": [
        "数据预处理\n",
        "\n",
        "\n",
        "数据的保存格式为：{ word1:[translation1,translation2,...], word2:[...],...}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9BiinrTx3kQ",
        "colab_type": "code",
        "outputId": "84617a31-55f4-4fbf-edd8-0c7987b05d02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "word_to_translation = defaultdict(list)  # our dictionary\n",
        "\n",
        "bos = '_'\n",
        "eos = ';'\n",
        "\n",
        "with open(\"main_dataset_small.txt\") as fin:\n",
        "    for line in fin:\n",
        "        en, he = line[:-1].lower().replace(bos, ' ').replace(eos,                                         ' ').split('\\t')\n",
        "        word, trans = (he, en) if MODE == 'he-to-en' else (en, he)\n",
        "        if len(word) < 3:\n",
        "            continue\n",
        "        if EASY_MODE:\n",
        "            if max(len(word), len(trans)) > 20:\n",
        "                continue\n",
        "        word_to_translation[word].append(trans)\n",
        "print(\"size = \", len(word_to_translation))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size =  486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFSd8pU50OKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all unique lines in source language\n",
        "all_words = np.array(list(word_to_translation.keys()))\n",
        "# get all unique lines in translation language\n",
        "all_translations = np.array(\n",
        "    [ts for all_ts in word_to_translation.values() for ts in all_ts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTe_bEzA07zU",
        "colab_type": "text"
      },
      "source": [
        "利用sklearn.model_selection中的工具分隔数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyVQwX1Z00tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_words, test_words = train_test_split(\n",
        "    all_words, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbMPM2Rc1DHR",
        "colab_type": "text"
      },
      "source": [
        "### 构造Vocab类。\n",
        "- 把字符转为数字\n",
        "- 把数字转为字符"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkU65bqC2Nhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, tokens, bos=\"__BOS__\", eos=\"__EOS__\", sep=''):\n",
        "        \"\"\"\n",
        "        A special class that handles tokenizing and detokenizing\n",
        "        \"\"\"\n",
        "        assert bos in tokens, eos in tokens\n",
        "        self.tokens = tokens\n",
        "        self.token_to_ix = {t: i for i, t in enumerate(tokens)}\n",
        "\n",
        "        self.bos = bos\n",
        "        self.bos_ix = self.token_to_ix[bos]\n",
        "        self.eos = eos\n",
        "        self.eos_ix = self.token_to_ix[eos]\n",
        "        self.sep = sep\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_lines(lines, bos=\"__BOS__\", eos=\"__EOS__\", sep=''):\n",
        "        flat_lines = sep.join(list(lines))\n",
        "        flat_lines = list(flat_lines.split(sep)) if sep else list(flat_lines)\n",
        "        tokens = list(set(sep.join(flat_lines)))\n",
        "        tokens = [t for t in tokens if t not in (bos, eos) and len(t) != 0]\n",
        "        tokens = [bos, eos] + tokens\n",
        "        return Vocab(tokens, bos, eos, sep)\n",
        "\n",
        "    def tokenize(self, string):\n",
        "        \"\"\"converts string to a list of tokens\"\"\"\n",
        "        tokens = list(filter(len, string.split(self.sep))) \\\n",
        "            if self.sep != '' else list(string)\n",
        "        return [self.bos] + tokens + [self.eos]\n",
        "\n",
        "    def to_matrix(self, lines, max_len=None):\n",
        "        \"\"\"\n",
        "        convert variable length token sequences into  fixed size matrix\n",
        "        example usage:\n",
        "        >>>print( as_matrix(words[:3],source_to_ix))\n",
        "        [[15 22 21 28 27 13 -1 -1 -1 -1 -1]\n",
        "         [30 21 15 15 21 14 28 27 13 -1 -1]\n",
        "         [25 37 31 34 21 20 37 21 28 19 13]]\n",
        "        \"\"\"\n",
        "        max_len = max_len or max(map(len, lines)) + 2  # 2 for bos and eos\n",
        "\n",
        "        matrix = np.zeros((len(lines), max_len), dtype='int32') + self.eos_ix\n",
        "        for i, seq in enumerate(lines):\n",
        "            tokens = self.tokenize(seq)\n",
        "            row_ix = list(map(self.token_to_ix.get, tokens))[:max_len]\n",
        "            matrix[i, :len(row_ix)] = row_ix\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    def to_lines(self, matrix, crop=True):\n",
        "        \"\"\"\n",
        "        Convert matrix of token ids into strings\n",
        "        :param matrix: matrix of tokens of int32, shape=[batch,time]\n",
        "        :param crop: if True, crops BOS and EOS from line\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        lines = []\n",
        "        for line_ix in map(list, matrix):\n",
        "            if crop:\n",
        "                if line_ix[0] == self.bos_ix:\n",
        "                    line_ix = line_ix[1:]\n",
        "                if self.eos_ix in line_ix:\n",
        "                    line_ix = line_ix[:line_ix.index(self.eos_ix)]\n",
        "            line = self.sep.join(self.tokens[i] for i in line_ix)\n",
        "            lines.append(line)\n",
        "        return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahuQvfEO1DqM",
        "colab_type": "code",
        "outputId": "d5285aa0-93f9-4c46-ff12-97f56ddcc203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "\n",
        "inp_voc = Vocab.from_lines(''.join(all_words), bos=bos, eos=eos, sep='')\n",
        "out_voc = Vocab.from_lines(''.join(all_translations), bos=bos, eos=eos, sep='')\n",
        "\n",
        "# Here's how you cast lines into ids and backwards.\n",
        "batch_lines = all_words[:5]\n",
        "batch_ids = inp_voc.to_matrix(batch_lines)\n",
        "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
        "\n",
        "print(\"lines\")\n",
        "print(batch_lines)\n",
        "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
        "print(batch_ids)\n",
        "print(\"\\nback to words\")\n",
        "print(batch_lines_restored)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines\n",
            "['אנרכיזם' 'אוטיזם קלאסי' 'אלבדו' 'אלבמה' 'אכילס']\n",
            "\n",
            "words to ids (0 = bos, 1 = eos):\n",
            "[[ 0 40 16 59 25 15 48 38  1  1  1  1  1  1]\n",
            " [ 0 40 36 43 15 48 38 46 17 41 40 30 15  1]\n",
            " [ 0 40 41  5 12 36  1  1  1  1  1  1  1  1]\n",
            " [ 0 40 41  5 33 11  1  1  1  1  1  1  1  1]\n",
            " [ 0 40 25 15 41 30  1  1  1  1  1  1  1  1]]\n",
            "\n",
            "back to words\n",
            "['אנרכיזם', 'אוטיזם קלאסי', 'אלבדו', 'אלבמה', 'אכילס']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59u-B03Q2FDR",
        "colab_type": "code",
        "outputId": "d31e5b90-57f1-4b90-9cbe-a846c0f61416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"words\")\n",
        "plt.hist(list(map(len, all_words)), bins=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('translations')\n",
        "plt.hist(list(map(len, all_translations)), bins=20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 7., 18., 35., 41., 45., 71.,  0., 68., 25., 28., 23., 20., 23.,\n",
              "         0., 17., 14., 17., 16., 13., 10.]),\n",
              " array([ 3.  ,  3.85,  4.7 ,  5.55,  6.4 ,  7.25,  8.1 ,  8.95,  9.8 ,\n",
              "        10.65, 11.5 , 12.35, 13.2 , 14.05, 14.9 , 15.75, 16.6 , 17.45,\n",
              "        18.3 , 19.15, 20.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAEICAYAAACHwyd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s0a-8ap3KfB",
        "colab_type": "text"
      },
      "source": [
        "### 3.实现Encoder-Decoder模型\n",
        "\n",
        "seq2seq模型model提供以下接口：\n",
        "- model.symbolic_translate(inp, **flags)-> out, logp：输入为：\n",
        "- model.symbolic_score(inp, out, **flags) -> logp\n",
        "- model.weights：所有层的权重。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ402oKX2VJ9",
        "colab_type": "code",
        "outputId": "a62d3521-9232-4f8c-fbc7-fc5ad4892a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "%tensorflow_version 1.x \n",
        "tf.reset_default_graph()\n",
        "s = tf.InteractiveSession()\n",
        "\n",
        "# ^^^ if you get \"variable *** already exists\": re-run this cell again"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0begV-4587",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 本部分实现单层的GRU encoder-decoder模型。\n",
        "# 注意事项：\n",
        "# 1: when using several recurrent layers TF can mixed up the weights of different recurrent layers.\n",
        "# In that case, make sure you both create AND use each rnn/gru/lstm/custom layer in a unique variable scope\n",
        "# e.g. with tf.variable_scope(\"first_lstm\"): new_cell, new_out = self.lstm_1(...)\n",
        "#      with tf.variable_scope(\"second_lstm\"): new_cell2, new_out2 = self.lstm_2(...)\n",
        "# Note 2: everything you need for decoding should be stored in model state (output list of both encode and decode)\n",
        "# e.g. for attention, you should store all encoder sequence and input mask\n",
        "# there in addition to lstm/gru states.\n",
        "\n",
        "class BasicTranslationModel:\n",
        "    def __init__(self, name, inp_voc, out_voc,\n",
        "                 emb_size, hid_size,):\n",
        "\n",
        "        self.name = name\n",
        "        self.inp_voc = inp_voc\n",
        "        self.out_voc = out_voc\n",
        "\n",
        "        with tf.variable_scope(name):\n",
        "            self.emb_inp = L.Embedding(len(inp_voc), emb_size)\n",
        "            self.emb_out = L.Embedding(len(out_voc), emb_size)\n",
        "            self.enc0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
        "            self.dec_start = L.Dense(hid_size)\n",
        "            self.dec0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
        "            self.logits = L.Dense(len(out_voc))\n",
        "\n",
        "            # run on dummy output to .build all layers (and therefore create\n",
        "            # weights)\n",
        "            inp = tf.placeholder('int32', [None, None])\n",
        "            out = tf.placeholder('int32', [None, None])\n",
        "            h0 = self.encode(inp)\n",
        "            h1 = self.decode(h0, out[:, 0])\n",
        "            # h2 = self.decode(h1,out[:,1]) etc.\n",
        "\n",
        "        self.weights = tf.get_collection(\n",
        "            tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
        "\n",
        "    def encode(self, inp, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic input sequence, computes initial state\n",
        "        :param inp: matrix of input tokens [batch, time]\n",
        "        :return: a list of initial decoder state tensors\n",
        "        \"\"\"\n",
        "        inp_lengths = infer_length(inp, self.inp_voc.eos_ix)\n",
        "        inp_emb = self.emb_inp(inp)\n",
        "\n",
        "        _, enc_last = tf.nn.dynamic_rnn(\n",
        "            self.enc0, inp_emb,\n",
        "            sequence_length=inp_lengths,\n",
        "            dtype=inp_emb.dtype)\n",
        "\n",
        "        dec_start = self.dec_start(enc_last)\n",
        "        return [dec_start]\n",
        "\n",
        "    def decode(self, prev_state, prev_tokens, **flags):\n",
        "        \"\"\"\n",
        "        Takes previous decoder state and tokens, returns new state and logits\n",
        "        :param prev_state: a list of previous decoder state tensors\n",
        "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
        "        :return: a list of next decoder state tensors, a tensor of logits [batch,n_tokens]\n",
        "        \"\"\"\n",
        "\n",
        "        [prev_dec] = prev_state\n",
        "\n",
        "        prev_emb = self.emb_out(prev_tokens[:, None])[:, 0]\n",
        "\n",
        "        new_dec_out, new_dec_state = self.dec0(prev_emb, prev_dec)\n",
        "\n",
        "        output_logits = self.logits(new_dec_out)\n",
        "\n",
        "        return [new_dec_state], output_logits\n",
        "\n",
        "    def symbolic_score(self, inp, out, eps=1e-30, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic int32 matrices of hebrew words and their english translations.\n",
        "        Computes the log-probabilities of all possible english characters given english prefices and hebrew word.\n",
        "        :param inp: input sequence, int32 matrix of shape [batch,time]\n",
        "        :param out: output sequence, int32 matrix of shape [batch,time]\n",
        "        :return: log-probabilities of all possible english characters of shape [bath,time,n_tokens]\n",
        "        NOTE: log-probabilities time axis  is synchronized with out\n",
        "        In other words, logp are probabilities of __current__ output at each tick, not the next one\n",
        "        therefore you can get likelihood as logprobas * tf.one_hot(out,n_tokens)\n",
        "        \"\"\"\n",
        "        first_state = self.encode(inp, **flags)\n",
        "\n",
        "        batch_size = tf.shape(inp)[0]\n",
        "        bos = tf.fill([batch_size], self.out_voc.bos_ix)\n",
        "        first_logits = tf.log(tf.one_hot(bos, len(self.out_voc)) + eps)\n",
        "\n",
        "        def step(blob, y_prev):\n",
        "            h_prev = blob[:-1]\n",
        "            h_new, logits = self.decode(h_prev, y_prev, **flags)\n",
        "            return list(h_new) + [logits]\n",
        "\n",
        "        results = tf.scan(step, initializer=list(first_state) + [first_logits],\n",
        "                          elems=tf.transpose(out))\n",
        "\n",
        "        # gather state and logits, each of shape [time,batch,...]\n",
        "        states_seq, logits_seq = results[:-1], results[-1]\n",
        "\n",
        "        # add initial state and logits\n",
        "        logits_seq = tf.concat((first_logits[None], logits_seq), axis=0)\n",
        "\n",
        "        # convert from [time,batch,...] to [batch,time,...]\n",
        "        logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
        "\n",
        "        return tf.nn.log_softmax(logits_seq)\n",
        "\n",
        "    def symbolic_translate(\n",
        "            self,\n",
        "            inp,\n",
        "            greedy=False,\n",
        "            max_len=None,\n",
        "            eps=1e-30,\n",
        "            **flags):\n",
        "        \"\"\"\n",
        "        takes symbolic int32 matrix of hebrew words, produces output tokens sampled\n",
        "        from the model and output log-probabilities for all possible tokens at each tick.\n",
        "        :param inp: input sequence, int32 matrix of shape [batch,time]\n",
        "        :param greedy: if greedy, takes token with highest probablity at each tick.\n",
        "            Otherwise samples proportionally to probability.\n",
        "        :param max_len: max length of output, defaults to 2 * input length\n",
        "        :return: output tokens int32[batch,time] and\n",
        "                 log-probabilities of all tokens at each tick, [batch,time,n_tokens]\n",
        "        \"\"\"\n",
        "        first_state = self.encode(inp, **flags)\n",
        "\n",
        "        batch_size = tf.shape(inp)[0]\n",
        "        bos = tf.fill([batch_size], self.out_voc.bos_ix)\n",
        "        first_logits = tf.log(tf.one_hot(bos, len(self.out_voc)) + eps)\n",
        "        max_len = tf.reduce_max(tf.shape(inp)[1]) * 2\n",
        "\n",
        "        def step(blob, t):\n",
        "            h_prev, y_prev = blob[:-2], blob[-1]\n",
        "            h_new, logits = self.decode(h_prev, y_prev, **flags)\n",
        "            y_new = (\n",
        "                tf.argmax(logits, axis=-1) if greedy\n",
        "                else tf.multinomial(logits, 1)[:, 0]\n",
        "            )\n",
        "            return list(h_new) + [logits, tf.cast(y_new, y_prev.dtype)]\n",
        "\n",
        "        results = tf.scan(\n",
        "            step,\n",
        "            initializer=list(first_state) + [first_logits, bos],\n",
        "            elems=[tf.range(max_len)],\n",
        "        )\n",
        "\n",
        "        # gather state, logits and outs, each of shape [time,batch,...]\n",
        "        states_seq, logits_seq, out_seq = (\n",
        "            results[:-2], results[-2], results[-1]\n",
        "        )\n",
        "\n",
        "        # add initial state, logits and out\n",
        "        logits_seq = tf.concat((first_logits[None], logits_seq), axis=0)\n",
        "        out_seq = tf.concat((bos[None], out_seq), axis=0)\n",
        "        states_seq = [\n",
        "            tf.concat((init[None], states), axis=0)\n",
        "            for init, states in zip(first_state, states_seq)\n",
        "        ]\n",
        "\n",
        "        # convert from [time,batch,...] to [batch,time,...]\n",
        "        logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
        "        out_seq = tf.transpose(out_seq)\n",
        "        states_seq = [\n",
        "            tf.transpose(states, [1, 0] + list(range(2, states.shape.ndims)))\n",
        "            for states in states_seq\n",
        "        ]\n",
        "\n",
        "        return out_seq, tf.nn.log_softmax(logits_seq)\n",
        "\n",
        "\n",
        "### Utility functions ###\n",
        "\n",
        "def initialize_uninitialized(sess=None):\n",
        "    \"\"\"\n",
        "    Initialize unitialized variables, doesn't affect those already initialized\n",
        "    :param sess: in which session to initialize stuff. Defaults to tf.get_default_session()\n",
        "    \"\"\"\n",
        "    sess = sess or tf.get_default_session()\n",
        "    global_vars = tf.global_variables()\n",
        "    is_not_initialized = sess.run(\n",
        "        [tf.is_variable_initialized(var) for var in global_vars]\n",
        "    )\n",
        "    not_initialized_vars = [\n",
        "        v for (v, f)\n",
        "        in zip(global_vars, is_not_initialized)\n",
        "        if not f\n",
        "    ]\n",
        "\n",
        "    if len(not_initialized_vars):\n",
        "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
        "\n",
        "\n",
        "def infer_length(seq, eos_ix, time_major=False, dtype=tf.int32):\n",
        "    \"\"\"\n",
        "    compute length given output indices and eos code\n",
        "    :param seq: tf matrix [time,batch] if time_major else [batch,time]\n",
        "    :param eos_ix: integer index of end-of-sentence token\n",
        "    :returns: lengths, int32 vector of shape [batch]\n",
        "    \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    is_eos = tf.cast(tf.equal(seq, eos_ix), dtype)\n",
        "    count_eos = tf.cumsum(is_eos, axis=axis, exclusive=True)\n",
        "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos, 0), dtype), axis=axis)\n",
        "    return lengths\n",
        "\n",
        "\n",
        "def infer_mask(seq, eos_ix, time_major=False, dtype=tf.float32):\n",
        "    \"\"\"\n",
        "    compute mask given output indices and eos code\n",
        "    :param seq: tf matrix [time,batch] if time_major else [batch,time]\n",
        "    :param eos_ix: integer index of end-of-sentence token\n",
        "    :returns: mask, float32 matrix with '0's and '1's of same shape as seq\n",
        "    \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    lengths = infer_length(seq, eos_ix, time_major=time_major)\n",
        "    mask = tf.sequence_mask(lengths, maxlen=tf.shape(seq)[axis], dtype=dtype)\n",
        "    if time_major:\n",
        "        mask = tf.transpose(mask)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def select_values_over_last_axis(values, indices):\n",
        "    \"\"\"\n",
        "    Auxiliary function to select logits corresponding to chosen tokens.\n",
        "    :param values: logits for all actions: float32[batch,tick,action]\n",
        "    :param indices: action ids int32[batch,tick]\n",
        "    :returns: values selected for the given actions: float[batch,tick]\n",
        "    \"\"\"\n",
        "    assert values.shape.ndims == 3 and indices.shape.ndims == 2\n",
        "    batch_size, seq_len = tf.shape(indices)[0], tf.shape(indices)[1]\n",
        "    batch_i = tf.tile(tf.range(0, batch_size)[:, None], [1, seq_len])\n",
        "    time_i = tf.tile(tf.range(0, seq_len)[None, :], [batch_size, 1])\n",
        "    indices_nd = tf.stack([batch_i, time_i, indices], axis=-1)\n",
        "\n",
        "    return tf.gather_nd(values, indices_nd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCK4NAw548gl",
        "colab_type": "code",
        "outputId": "48309261-4dbc-4a28-d404-f25f771c283e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "model = BasicTranslationModel('model', inp_voc, out_voc,emb_size=64, hid_size=128)\n",
        "\n",
        "s.run(tf.global_variables_initializer())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-12-6e4051d81ac1>:13: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From <ipython-input-12-6e4051d81ac1>:41: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxkbBoAO_tu-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6L1DRZu5DEr",
        "colab_type": "code",
        "outputId": "3ca833bb-913d-44c1-dbce-28415b51176c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Play around with symbolic_translate and symbolic_score\n",
        "inp = tf.placeholder_with_default(np.random.randint(\n",
        "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
        "out = tf.placeholder_with_default(np.random.randint(\n",
        "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
        "\n",
        "# translate inp (with untrained model)\n",
        "sampled_out, logp = model.symbolic_translate(inp, greedy=False)\n",
        "print(\"\\nSymbolic_translate output:\\n\", sampled_out, logp)\n",
        "print(\"\\nSample translations:\\n\", s.run(sampled_out))\n",
        "\n",
        "# score logp(out | inp) with untrained input\n",
        "logp = model.symbolic_score(inp, out)\n",
        "print(\"\\nSymbolic_score output:\\n\", logp)\n",
        "print(\"\\nLog-probabilities (clipped):\\n\", s.run(logp)[:, :2, :5])\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-6e4051d81ac1>:129: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "\n",
            "Symbolic_translate output:\n",
            " Tensor(\"transpose_1:0\", shape=(?, ?), dtype=int32) Tensor(\"LogSoftmax:0\", shape=(?, ?, 49), dtype=float32)\n",
            "\n",
            "Sample translations:\n",
            " [[ 0 40 18  0 40 15 23 41 45 35 11]\n",
            " [ 0 40 39 42 32  0  1 37 21 44 29]\n",
            " [ 0 44 31 44 11 40 34 17 23 37 30]]\n",
            "\n",
            "Symbolic_score output:\n",
            " Tensor(\"LogSoftmax_1:0\", shape=(?, ?, 49), dtype=float32)\n",
            "\n",
            "Log-probabilities (clipped):\n",
            " [[[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -3.8998256  -3.8996816  -3.8867202  -3.8948948  -3.8827703]]\n",
            "\n",
            " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -3.9098372  -3.8849895  -3.894798   -3.8878574  -3.885652 ]]\n",
            "\n",
            " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -3.9117277  -3.9058156  -3.8916981  -3.898558   -3.889639 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckx5mX165OpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare any operations you want here\n",
        "input_sequence = tf.placeholder('int32', [None, None])\n",
        "greedy_translations, logp = model.symbolic_translate(input_sequence, greedy=True)\n",
        "\n",
        "\n",
        "def translate(lines):\n",
        "    \"\"\"\n",
        "    You are given a list of input lines. \n",
        "    Make your neural network translate them.\n",
        "    :return: a list of output lines\n",
        "    \"\"\"\n",
        "    # Convert lines to a matrix of indices\n",
        "    lines_ix = inp_voc.to_matrix(lines)\n",
        "    print(\"lines_ix shape={}\".format(lines_ix.shape))\n",
        "\n",
        "    # Compute translations in form of indices\n",
        "    trans_ix = s.run(greedy_translations, {input_sequence:lines_ix})\n",
        "\n",
        "    # Convert translations back into strings\n",
        "    return out_voc.to_lines(trans_ix)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLbPm9mG5bDj",
        "colab_type": "code",
        "outputId": "aa51172d-e356-434f-ac52-01b4668717d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(\"Sample inputs:\", all_words[:3])\n",
        "print(\"Dummy translations:\", translate(all_words[:3]))\n",
        "\n",
        "assert isinstance(greedy_translations,\n",
        "                  tf.Tensor) and greedy_translations.dtype.is_integer, \"trans must be a tensor of integers (token ids)\"\n",
        "assert translate(all_words[:3]) == translate(\n",
        "    all_words[:3]), \"make sure translation is deterministic (use greedy=True and disable any noise layers)\"\n",
        "assert type(translate(all_words[:3])) is list and (type(translate(all_words[:1])[0]) is str or type(\n",
        "    translate(all_words[:1])[0]) is unicode), \"translate(lines) must return a sequence of strings!\"\n",
        "print(\"Tests passed!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample inputs: ['אנרכיזם' 'אוטיזם קלאסי' 'אלבדו']\n",
            "lines_ix shape=(3, 14)\n",
            "Dummy translations: ['ëëé22iii2iiiq-ccccq-q----ddz', '4jsst8mwwwwwwwwjjèèàèà__eëë2', '4js8t8mwwwwwwjkjèàèàèà__eëë2']\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(1, 9)\n",
            "Tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmb_E_hdaHTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 打分函数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U1ATUqRaC-e",
        "colab_type": "code",
        "outputId": "8f9b78a0-a0e9-472a-9d51-488b85e55141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install editdistance\n",
        "import editdistance  # !pip install editdistance\n",
        "\n",
        "\n",
        "def get_distance(word, trans):\n",
        "    \"\"\"\n",
        "    A function that takes word and predicted translation\n",
        "    and evaluates (Levenshtein's) edit distance to closest correct translation\n",
        "    \"\"\"\n",
        "    references = word_to_translation[word]\n",
        "    assert len(references) != 0, \"wrong/unknown word\"\n",
        "    return min(editdistance.eval(trans, ref) for ref in references)\n",
        "\n",
        "\n",
        "def score(words, bsize=8):\n",
        "    \"\"\"a function that computes levenshtein distance for bsize random samples\"\"\"\n",
        "    assert isinstance(words, np.ndarray)\n",
        "\n",
        "    batch_words = np.random.choice(words, size=bsize, replace=False)\n",
        "    batch_trans = translate(batch_words)\n",
        "\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "\n",
        "    return np.array(distances, dtype='float32')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFfU773QaNZ6",
        "colab_type": "code",
        "outputId": "94adcb46-ba54-48f5-8781-3bcc12ff15e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "[score(test_words, 10).mean() for _ in range(5)]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(10, 16)\n",
            "lines_ix shape=(10, 16)\n",
            "lines_ix shape=(10, 17)\n",
            "lines_ix shape=(10, 20)\n",
            "lines_ix shape=(10, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[31.5, 31.5, 33.0, 35.6, 37.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adu6CLgHaWjO",
        "colab_type": "text"
      },
      "source": [
        "### 开始训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEKkRyRaVza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import utility functions\n",
        "#from basic_model_tf import initialize_uninitialized, infer_length, infer_mask, select_values_over_last_axis\n",
        "\n",
        "\n",
        "class supervised_training:\n",
        "\n",
        "    # variable for inputs and correct answers\n",
        "    input_sequence = tf.placeholder('int32', [None, None])\n",
        "    reference_answers = tf.placeholder('int32', [None, None])\n",
        "\n",
        "    # Compute log-probabilities of all possible tokens at each step. Use model interface.\n",
        "    logprobs_seq = model.symbolic_score(input_sequence, reference_answers)\n",
        "\n",
        "    # compute mean crossentropy\n",
        "    crossentropy = - select_values_over_last_axis(logprobs_seq, reference_answers)\n",
        "\n",
        "    mask = infer_mask(reference_answers, out_voc.eos_ix)\n",
        "\n",
        "    loss = tf.reduce_sum(crossentropy * mask)/tf.reduce_sum(mask)\n",
        "\n",
        "    # Build weights optimizer. Use model.weights to get all trainable params.\n",
        "    train_step = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "\n",
        "# intialize optimizer params while keeping model intact\n",
        "initialize_uninitialized(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2njBSnaRM8",
        "colab_type": "code",
        "outputId": "d4331513-d8ea-45c7-f6f1-dd3f1d9df244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def sample_batch(words, word_to_translation, batch_size):\n",
        "    \"\"\"\n",
        "    sample random batch of words and random correct translation for each word\n",
        "    example usage:\n",
        "    batch_x,batch_y = sample_batch(train_words, word_to_translations,10)\n",
        "    \"\"\"\n",
        "    # choose words\n",
        "    batch_words = np.random.choice(words, size=batch_size)\n",
        "\n",
        "    # choose translations\n",
        "    batch_trans_candidates = list(map(word_to_translation.get, batch_words))\n",
        "    batch_trans = list(map(random.choice, batch_trans_candidates))\n",
        "\n",
        "    return inp_voc.to_matrix(batch_words), out_voc.to_matrix(batch_trans)\n",
        "    \n",
        "bx, by = sample_batch(train_words, word_to_translation, batch_size=3)\n",
        "print(\"Source:\")\n",
        "print(bx)\n",
        "print(\"Target:\")\n",
        "print(by)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source:\n",
            "[[ 0 40 41 30 16 12 59 36 46 36 36 41 43 11  1]\n",
            " [ 0 40 41 17 40 56  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  2 28 53 18 18  1  1  1  1  1  1  1  1  1]]\n",
            "Target:\n",
            "[[ 0  2 26 13 15 15  2 41 22  5 14 32 21 14 26 47  2  1]\n",
            " [ 0  2 26 25  2 41 13  1  1  1  1  1  1  1  1  1  1  1]\n",
            " [ 0  2 15 40  6  6  1  1  1  1  1  1  1  1  1  1  1  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg643JAeksHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e03c6d04-32df-4a55-c037-ac1752c599ed"
      },
      "source": [
        "len(word_to_translation)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "486"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QU7Jp9Yaseu",
        "colab_type": "code",
        "outputId": "4dff2d70-9bef-45bc-d2e0-9ef1b941ac15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange  # or use tqdm_notebook,tnrange\n",
        "\n",
        "loss_history = []\n",
        "editdist_history = []\n",
        "\n",
        "for i in trange(25000):\n",
        "    bx, by = sample_batch(train_words, word_to_translation, 16)\n",
        "\n",
        "    feed_dict = {\n",
        "        supervised_training.input_sequence: bx,\n",
        "        supervised_training.reference_answers: by\n",
        "    }\n",
        "\n",
        "    loss, _ = s.run([supervised_training.loss,\n",
        "                     supervised_training.train_step], feed_dict)\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    if (i+1) % REPORT_FREQ == 0:\n",
        "        clear_output(True)\n",
        "        current_scores = score(test_words)\n",
        "        editdist_history.append(current_scores.mean())\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(131)\n",
        "        plt.title('train loss / traning time')\n",
        "        plt.plot(loss_history)\n",
        "        plt.grid()\n",
        "        plt.subplot(132)\n",
        "        plt.title('val score distribution')\n",
        "        plt.hist(current_scores, bins=20)\n",
        "        plt.subplot(133)\n",
        "        plt.title('val score / traning time')\n",
        "        plt.plot(editdist_history)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        print(\"llh=%.3f, mean score=%.3f\" %\n",
        "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))\n",
        "\n",
        "# Note: it's okay if loss oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(8, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAEICAYAAABYl+LRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP94AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 4003/25000 [02:56<24:42, 14.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "llh=0.013, mean score=7.188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 4021/25000 [02:57<15:37, 22.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-52d5d045618a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     loss, _ = s.run([supervised_training.loss,\n\u001b[0;32m---> 16\u001b[0;31m                      supervised_training.train_step], feed_dict)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpTUM6v6avXQ",
        "colab_type": "code",
        "outputId": "c85163b3-d53b-4339-efe9-8b23034a812b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "for word in train_words[:10]:\n",
        "    print(\"%s -> %s\" % (word, translate([word])[0]))\n",
        "\n",
        "test_scores = []\n",
        "for start_i in trange(0, len(test_words), 32):\n",
        "    batch_words = test_words[start_i:start_i+32]\n",
        "    batch_trans = translate(batch_words)\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "    test_scores.extend(distances)\n",
        "\n",
        "print(\"Supervised test score:\", np.mean(test_scores))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(1, 12)\n",
            "הצעה צנועה -> a modest proposal\n",
            "lines_ix shape=(1, 12)\n",
            "אפטוזאורוס -> apatosaurus\n",
            "lines_ix shape=(1, 6)\n",
            "אשור -> assyria\n",
            "lines_ix shape=(1, 14)\n",
            "מרוץ מכוניות -> auto racing\n",
            "lines_ix shape=(1, 10)\n",
            "אן ארבור -> michigan ann arbor\n",
            "lines_ix shape=(1, 12)\n",
            "21 באוגוסט -> august 21\n",
            "lines_ix shape=(1, 10)\n",
            "אפרודיטה -> aphrodite\n",
            "lines_ix shape=(1, 7)\n",
            "אפריל -> april\n",
            "lines_ix shape=(1, 11)\n",
            "אל-קאעידה -> al-qaeda\n",
            "lines_ix shape=(1, 9)\n",
            "אסתטיקה -> aesthetics\n",
            "lines_ix shape=(32, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2/2 [00:00<00:00, 25.49it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(17, 21)\n",
            "Supervised test score: 7.224489795918367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWG4okZgeu21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQrTTe7njmcY",
        "colab_type": "text"
      },
      "source": [
        "### 自定义损失函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyz9hoHMn7J-",
        "colab_type": "code",
        "outputId": "4d2ac350-342f-405a-d13e-f6415f8194b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "editdistance.eval('abc', 'cde')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBBaRAbkkIw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_ix_to_token = dict([(v,k) for k, v in inp_voc.token_to_ix.items()])\n",
        "trans_ix_to_token = dict([v,k] for k, v in out_voc.token_to_ix.items())\n",
        "def _compute_levenshtein(words_ix, trans_ix):\n",
        "    \"\"\"\n",
        "    A custom tensorflow operation that computes levenshtein loss for predicted trans.\n",
        "\n",
        "    Params:\n",
        "    - words_ix - a matrix of letter indices, shape=[batch_size,word_length]\n",
        "    - words_mask - a matrix of zeros/ones, \n",
        "       1 means \"word is still not finished\"\n",
        "       0 means \"word has already finished and this is padding\"\n",
        "\n",
        "    - trans_mask - a matrix of output letter indices, shape=[batch_size,translation_length]\n",
        "    - trans_mask - a matrix of zeros/ones, similar to words_mask but for trans_ix\n",
        "\n",
        "\n",
        "    Please implement the function and make sure it passes tests from the next cell.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # convert words to strings\n",
        "    words = [[words_ix_to_token[w] for w in word] for word in words_ix]\n",
        "    words = [\"\".join(word) for word in words]\n",
        "\n",
        "    assert type(words) is list and type(\n",
        "        words[0]) is str and len(words) == len(words_ix)\n",
        "\n",
        "    # convert translations to lists\n",
        "    translations = [[trans_ix_to_token[t] for t in tran] for tran in trans_ix]\n",
        "    translations=[\"\".join(tran) for tran in translations]\n",
        "    #print(translations[0])\n",
        "\n",
        "    assert type(translations) is list and type(\n",
        "        translations[0]) is str and len(translations) == len(trans_ix)\n",
        "\n",
        "    # computes levenstein distances. can be arbitrary python code.\n",
        "    distances = [editdistance.eval(w, t) for w, t in zip(words, translations)]\n",
        "\n",
        "    assert type(distances) in (list, tuple, np.ndarray) and len(\n",
        "        distances) == len(words_ix)\n",
        "\n",
        "    distances = np.array(list(distances), dtype='float32')\n",
        "    return distances\n",
        "\n",
        "def compute_levenshtein(words_ix, trans_ix):\n",
        "    out = tf.py_func(_compute_levenshtein, [words_ix, trans_ix, ], tf.float32)\n",
        "    out.set_shape([None])\n",
        "\n",
        "    return tf.stop_gradient(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgF-I-0mp0HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQIItqBk3DI",
        "colab_type": "code",
        "outputId": "becb7f37-3997-4f3e-9df6-e98b88c20fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# 测试上面代码\n",
        "# test suite\n",
        "# sample random batch of (words, correct trans, wrong trans)\n",
        "batch_words = np.random.choice(train_words, size=100)\n",
        "\n",
        "batch_trans = list(map(random.choice, map(\n",
        "    word_to_translation.get, batch_words)))\n",
        "batch_trans_wrong = np.random.choice(all_translations, size=100)\n",
        "\n",
        "batch_words_ix = tf.constant(inp_voc.to_matrix(batch_words))\n",
        "batch_trans_ix = tf.constant(out_voc.to_matrix(batch_trans))\n",
        "batch_trans_wrong_ix = tf.constant(out_voc.to_matrix(batch_trans_wrong))\n",
        "\n",
        "# assert compute_levenshtein is zero for ideal translations\n",
        "correct_answers_score = compute_levenshtein(\n",
        "    batch_words_ix, batch_trans_ix).eval()\n",
        "print(\"score={}\".format(correct_answers_score))\n",
        "#assert np.all(correct_answers_score ==0), \"a perfect translation got nonzero levenshtein score!\"\n",
        "\n",
        "print(\"Everything seems alright!\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-d36dede4c5a0>:46: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "score=[ 5.  9. 13.  8.  6. 11.  8. 13. 14. 10. 12. 10.  7.  8.  7. 13. 11. 13.\n",
            " 15.  9. 10.  6.  8. 18. 20.  7.  8. 13.  9. 13.  8. 16. 10.  9. 13.  8.\n",
            "  8. 14.  9.  9. 13.  9. 10. 15. 19.  9. 12.  9. 12.  7.  4. 14. 13.  9.\n",
            " 13. 11. 11. 11.  8. 14.  9. 10. 18. 17. 17. 17. 17. 14. 10. 11. 13. 20.\n",
            "  9. 14.  5.  7.  8.  9. 13.  6.  7. 10. 12.  8.  7. 20. 10.  9. 18. 17.\n",
            " 18. 14.  8. 10.  9.  6. 10.  8. 11. 20.]\n",
            "Everything seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb43aEjYot9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iNrSX4r3QL",
        "colab_type": "text"
      },
      "source": [
        "### self-critical policy gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecBY47tsMkb",
        "colab_type": "text"
      },
      "source": [
        "实现 self-critical sequence training.[论文](https://arxiv.org/abs/1612.00563)\n",
        "\n",
        "policy-based的优化方法，但是b的计算方法有点不一样。\n",
        "\n",
        "$$ \\nabla J = E_{x \\sim p(s)} E_{y \\sim \\pi(y|x)} \\nabla log \\pi(y|x) \\cdot (R(x,y) - b(x)) $$\n",
        "reward R(x,y)为负编辑距离，因为我们是最小化J。 \n",
        "\n",
        "The baseline b(x) represents how well model fares on word x.\n",
        "\n",
        "In practice, this means that we compute baseline as a score of greedy translation, $b(x) = R(x,y_{greedy}(x)) $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKLTJO6MMyDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HHu9aYcr9AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class trainer:\n",
        "\n",
        "    input_sequence = tf.placeholder('int32', [None, None])\n",
        "\n",
        "    # use model to __sample__ symbolic translations given input_sequence\n",
        "    sample_translations, sample_logp = model.symbolic_translate(input_sequence, greedy=False)\n",
        "    # use model to __greedy__ symbolic translations given input_sequence\n",
        "    greedy_translations, greedy_logp = model.symbolic_translate(input_sequence, greedy=True)\n",
        "\n",
        "    rewards = - compute_levenshtein(input_sequence, sample_translations)\n",
        "\n",
        "    # compute __negative__ levenshtein for greedy mode\n",
        "    baseline = - compute_levenshtein(input_sequence, greedy_translations)\n",
        "\n",
        "    # compute advantage using rewards and baseline\n",
        "    advantage = rewards - baseline\n",
        "    assert advantage.shape.ndims == 1, \"advantage must be of shape [batch_size]\"\n",
        "\n",
        "    # compute log_pi(a_t|s_t), shape = [batch, seq_length]\n",
        "    logprobs_phoneme = # YOUR CODE\n",
        "    # ^-- hint: look at how crossentropy is implemented in supervised learning loss above\n",
        "    # mind the sign - this one should not be multiplied by -1 :)\n",
        "\n",
        "\n",
        "    # Compute policy gradient\n",
        "    # or rather surrogate function who's gradient is policy gradient\n",
        "    J = logprobs_phoneme*advantage[:, None]\n",
        "\n",
        "    mask = infer_mask(sample_translations, out_voc.eos_ix)\n",
        "    loss = - tf.reduce_sum(J*mask) / tf.reduce_sum(mask)\n",
        "\n",
        "    # regularize with negative entropy. Don't forget the sign!\n",
        "    # note: for entropy you need probabilities for all tokens (sample_logp), not just phoneme_logprobs\n",
        "    entropy = <compute entropy matrix of shape[batch, seq_length], H = -sum(p*log_p), don't forget the sign!>\n",
        "    # hint: you can get sample probabilities from sample_logp using math :)\n",
        "\n",
        "\n",
        "    assert entropy.shape.ndims == 2, \"please make sure elementwise entropy is of shape [batch,time]\"\n",
        "\n",
        "    loss -= 0.01*tf.reduce_sum(entropy*mask) / tf.reduce_sum(mask)\n",
        "\n",
        "    # compute weight updates, clip by norm\n",
        "    grads = tf.gradients(loss, model.weights)\n",
        "    grads = tf.clip_by_global_norm(grads, 50)[0]\n",
        "\n",
        "    train_step = tf.train.AdamOptimizer(\n",
        "        learning_rate=1e-5).apply_gradients(zip(grads, model.weights,))\n",
        "\n",
        "\n",
        "initialize_uninitialized()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9iuxCm1tNc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in trange(100000):\n",
        "    bx = sample_batch(train_words, word_to_translation, 32)[0]\n",
        "    pseudo_loss, _ = s.run([trainer.loss, trainer.train_step], {\n",
        "                           trainer.input_sequence: bx})\n",
        "\n",
        "    loss_history.append(\n",
        "        pseudo_loss\n",
        "    )\n",
        "\n",
        "    if (i+1) % REPORT_FREQ == 0:\n",
        "        clear_output(True)\n",
        "        current_scores = score(test_words)\n",
        "        editdist_history.append(current_scores.mean())\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(121)\n",
        "        plt.title('val score distribution')\n",
        "        plt.hist(current_scores, bins=20)\n",
        "        plt.subplot(122)\n",
        "        plt.title('val score / traning time')\n",
        "        plt.plot(editdist_history)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        print(\"J=%.3f, mean score=%.3f\" %\n",
        "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5xg4sH5tQsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 测试\n",
        "for word in train_words[:10]:\n",
        "    print(\"%s -> %s\" % (word, translate([word])[0]))\n",
        "\n",
        "test_scores = []\n",
        "for start_i in trange(0, len(test_words), 32):\n",
        "    batch_words = test_words[start_i:start_i+32]\n",
        "    batch_trans = translate(batch_words)\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "    test_scores.extend(distances)\n",
        "print(\"Supervised test score:\", np.mean(test_scores))\n",
        "\n",
        "# ^^ If you get Out Of Memory, please replace this with batched computation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66zxpiYtiTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KII4datjAB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Step 6: Make it actually work (5++ pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmjyGpsmsl1N",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/do_something_scst.png width=400>\n",
        "\n",
        "In this section we want you to finally __restart with EASY_MODE=False__ and experiment to find a good model/curriculum for that task.\n",
        "\n",
        "We recommend you to start with the following architecture\n",
        "\n",
        "```\n",
        "encoder---decoder\n",
        "\n",
        "           P(y|h)\n",
        "             ^\n",
        " LSTM  ->   LSTM\n",
        "  ^          ^\n",
        " biLSTM  ->   LSTM\n",
        "  ^          ^\n",
        "input       y_prev\n",
        "```\n",
        "\n",
        "__Note:__ you can fit all 4 state tensors of both LSTMs into a in a single state - just assume that it contains, for example, [h0, c0, h1, c1] - pack it in encode and update in decode.\n",
        "\n",
        "Here are some cool ideas on what you can do then.\n",
        "\n",
        "__General tips & tricks:__\n",
        "* In some tensorflow versions and for some layers, it is required that each rnn/gru/lstm cell gets it's own `tf.variable_scope(unique_name, reuse=False)`.\n",
        "  * Otherwise it will complain about wrong tensor sizes because it tries to reuse weights from one rnn to the other.\n",
        "* You will likely need to adjust pre-training time for such a network.\n",
        "* Supervised pre-training may benefit from clipping gradients somehow.\n",
        "* SCST may indulge a higher learning rate in some cases and changing entropy regularizer over time.\n",
        "* It's often useful to save pre-trained model parameters to not re-train it every time you want new policy gradient parameters. \n",
        "* When leaving training for nighttime, try setting REPORT_FREQ to a larger value (e.g. 500) not to waste time on it.\n",
        "\n",
        "\n",
        "\n",
        "__Formal criteria:__\n",
        "To get 5 points we want you to build an architecture that:\n",
        "* _doesn't consist of single GRU_\n",
        "* _works better_ than single GRU baseline. \n",
        "* We also want you to provide either learning curve or trained model, preferably both\n",
        "* ... and write a brief report or experiment log describing what you did and how it fared.\n",
        "\n",
        "### Attention\n",
        "There's more than one way to connect decoder to encoder\n",
        "  * __Vanilla:__ layer_i of encoder last state goes to layer_i of decoder initial state\n",
        "  * __Every tick:__ feed encoder last state _on every iteration_ of decoder.\n",
        "  * __Attention:__ allow decoder to \"peek\" at one (or several) positions of encoded sequence on every tick.\n",
        "    \n",
        "The most effective (and cool) of those is, of course, attention.\n",
        "You can read more about attention [in this nice blog post](https://distill.pub/2016/augmented-rnns/). The easiest way to begin is to use \"soft\" attention with \"additive\" or \"dot-product\" intermediate layers.\n",
        "\n",
        "__Tips__\n",
        "* Model usually generalizes better if you no longer allow decoder to see final encoder state\n",
        "* Once your model made it through several epochs, it is a good idea to visualize attention maps to understand what your model has actually learned\n",
        "\n",
        "* There's more stuff [here](https://github.com/yandexdataschool/Practical_RL/blob/master/week8_scst/bonus.ipynb)\n",
        "* If you opted for hard attention, we recommend [gumbel-softmax](https://blog.evjang.com/2016/11/tutorial-categorical-variational.html) instead of sampling. Also please make sure soft attention works fine before you switch to hard.\n",
        "\n",
        "\n",
        "### UREX\n",
        "* This is a way to improve exploration in policy-based settings. The main idea is that you find and upweight under-appreciated actions.\n",
        "* Here's [video](https://www.youtube.com/watch?v=fZNyHoXgV7M&feature=youtu.be&t=3444)\n",
        " and an [article](https://arxiv.org/abs/1611.09321).\n",
        "* You may want to reduce batch size 'cuz UREX requires you to sample multiple times per source sentence.\n",
        "* Once you got it working, try using experience replay with importance sampling instead of (in addition to) basic UREX.\n",
        "\n",
        "### Some additional ideas:\n",
        "* (advanced deep learning) It may be a good idea to first train on small phrases and then adapt to larger ones (a.k.a. training curriculum).\n",
        "* (advanced nlp) You may want to switch from raw utf8 to something like unicode or even syllables to make task easier.\n",
        "* (advanced nlp) Since hebrew words are written __with vowels omitted__, you may want to use a small Hebrew vowel markup dataset at `he-pron-wiktionary.txt`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-olFslBuRap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}