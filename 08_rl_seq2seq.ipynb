{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_rl_seq2seq.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/450586509/reinforcement-learning-practice/blob/master/08_rl_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDydjcUQyNI5",
        "colab_type": "text"
      },
      "source": [
        "#### 任务 \n",
        "Hebrew->English machine translation for words and short phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVRYmV1dyEMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If True, only translates phrases shorter than 20 characters (way easier).\n",
        "EASY_MODE = True\n",
        "# Useful for initial coding.\n",
        "# If false, works with all phrases (please switch to this mode for homework assignment)\n",
        "\n",
        "MODE = \"he-to-en\"  # way we translate. Either \"he-to-en\" or \"en-to-he\"\n",
        "# maximal length of _generated_ output, does not affect training\n",
        "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20\n",
        "REPORT_FREQ = 100  # how often to evaluate validation score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5WR2Gde6tfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cHHaS1Qz-no",
        "colab_type": "text"
      },
      "source": [
        "数据预处理\n",
        "\n",
        "\n",
        "数据的保存格式为：{ word1:[translation1,translation2,...], word2:[...],...}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9BiinrTx3kQ",
        "colab_type": "code",
        "outputId": "d04c74a0-fcd1-469a-dd82-248d3151fada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "word_to_translation = defaultdict(list)  # our dictionary\n",
        "\n",
        "bos = '_'\n",
        "eos = ';'\n",
        "\n",
        "with open(\"main_dataset.txt\") as fin:\n",
        "    for line in fin:\n",
        "        en, he = line[:-1].lower().replace(bos, ' ').replace(eos,                                         ' ').split('\\t')\n",
        "        word, trans = (he, en) if MODE == 'he-to-en' else (en, he)\n",
        "        if len(word) < 3:\n",
        "            continue\n",
        "        if EASY_MODE:\n",
        "            if max(len(word), len(trans)) > 20:\n",
        "                continue\n",
        "        word_to_translation[word].append(trans)\n",
        "print(\"size = \", len(word_to_translation))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size =  61205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPLlW12k23aa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZGKLt00pun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK8aTf1B1fSx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFSd8pU50OKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all unique lines in source language\n",
        "all_words = np.array(list(word_to_translation.keys()))\n",
        "# get all unique lines in translation language\n",
        "all_translations = np.array(\n",
        "    [ts for all_ts in word_to_translation.values() for ts in all_ts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTe_bEzA07zU",
        "colab_type": "text"
      },
      "source": [
        "split the dataset\n",
        "\n",
        "\n",
        "We hold out 10% of all words to be used for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyVQwX1Z00tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_words, test_words = train_test_split(\n",
        "    all_words, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngQwTAuS00VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbMPM2Rc1DHR",
        "colab_type": "text"
      },
      "source": [
        "### Building vocabularies\n",
        "\n",
        "We now need to build vocabularies that map strings to token ids and vice versa. We're gonna need these fellas when we feed training data into model or convert output matrices into english words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkU65bqC2Nhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, tokens, bos=\"__BOS__\", eos=\"__EOS__\", sep=''):\n",
        "        \"\"\"\n",
        "        A special class that handles tokenizing and detokenizing\n",
        "        \"\"\"\n",
        "        assert bos in tokens, eos in tokens\n",
        "        self.tokens = tokens\n",
        "        self.token_to_ix = {t: i for i, t in enumerate(tokens)}\n",
        "\n",
        "        self.bos = bos\n",
        "        self.bos_ix = self.token_to_ix[bos]\n",
        "        self.eos = eos\n",
        "        self.eos_ix = self.token_to_ix[eos]\n",
        "        self.sep = sep\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_lines(lines, bos=\"__BOS__\", eos=\"__EOS__\", sep=''):\n",
        "        flat_lines = sep.join(list(lines))\n",
        "        flat_lines = list(flat_lines.split(sep)) if sep else list(flat_lines)\n",
        "        tokens = list(set(sep.join(flat_lines)))\n",
        "        tokens = [t for t in tokens if t not in (bos, eos) and len(t) != 0]\n",
        "        tokens = [bos, eos] + tokens\n",
        "        return Vocab(tokens, bos, eos, sep)\n",
        "\n",
        "    def tokenize(self, string):\n",
        "        \"\"\"converts string to a list of tokens\"\"\"\n",
        "        tokens = list(filter(len, string.split(self.sep))) \\\n",
        "            if self.sep != '' else list(string)\n",
        "        return [self.bos] + tokens + [self.eos]\n",
        "\n",
        "    def to_matrix(self, lines, max_len=None):\n",
        "        \"\"\"\n",
        "        convert variable length token sequences into  fixed size matrix\n",
        "        example usage:\n",
        "        >>>print( as_matrix(words[:3],source_to_ix))\n",
        "        [[15 22 21 28 27 13 -1 -1 -1 -1 -1]\n",
        "         [30 21 15 15 21 14 28 27 13 -1 -1]\n",
        "         [25 37 31 34 21 20 37 21 28 19 13]]\n",
        "        \"\"\"\n",
        "        max_len = max_len or max(map(len, lines)) + 2  # 2 for bos and eos\n",
        "\n",
        "        matrix = np.zeros((len(lines), max_len), dtype='int32') + self.eos_ix\n",
        "        for i, seq in enumerate(lines):\n",
        "            tokens = self.tokenize(seq)\n",
        "            row_ix = list(map(self.token_to_ix.get, tokens))[:max_len]\n",
        "            matrix[i, :len(row_ix)] = row_ix\n",
        "\n",
        "        return matrix\n",
        "\n",
        "    def to_lines(self, matrix, crop=True):\n",
        "        \"\"\"\n",
        "        Convert matrix of token ids into strings\n",
        "        :param matrix: matrix of tokens of int32, shape=[batch,time]\n",
        "        :param crop: if True, crops BOS and EOS from line\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        lines = []\n",
        "        for line_ix in map(list, matrix):\n",
        "            if crop:\n",
        "                if line_ix[0] == self.bos_ix:\n",
        "                    line_ix = line_ix[1:]\n",
        "                if self.eos_ix in line_ix:\n",
        "                    line_ix = line_ix[:line_ix.index(self.eos_ix)]\n",
        "            line = self.sep.join(self.tokens[i] for i in line_ix)\n",
        "            lines.append(line)\n",
        "        return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK1I0kpqlyXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7737c4e1-8d15-4807-f6aa-a0d26ee2f0da"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'אוטיזם קלאסי'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahuQvfEO1DqM",
        "colab_type": "code",
        "outputId": "f52db8e0-b76e-4e77-e0ab-e7a48e12dea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "\n",
        "inp_voc = Vocab.from_lines(''.join(all_words), bos=bos, eos=eos, sep='')\n",
        "out_voc = Vocab.from_lines(''.join(all_translations), bos=bos, eos=eos, sep='')\n",
        "\n",
        "# Here's how you cast lines into ids and backwards.\n",
        "batch_lines = all_words[:5]\n",
        "batch_ids = inp_voc.to_matrix(batch_lines)\n",
        "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
        "\n",
        "print(\"lines\")\n",
        "print(batch_lines)\n",
        "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
        "print(batch_ids)\n",
        "print(\"\\nback to words\")\n",
        "print(batch_lines_restored)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines\n",
            "['אנרכיזם' 'אוטיזם קלאסי' 'אלבדו' 'אלבמה' 'אכילס']\n",
            "\n",
            "words to ids (0 = bos, 1 = eos):\n",
            "[[ 0 46 70 10 83  5 50 85  1  1  1  1  1  1]\n",
            " [ 0 46  6 48  5 50 85 21 27 40 46 41  5  1]\n",
            " [ 0 46 40 26 30  6  1  1  1  1  1  1  1  1]\n",
            " [ 0 46 40 26 17  7  1  1  1  1  1  1  1  1]\n",
            " [ 0 46 83  5 40 41  1  1  1  1  1  1  1  1]]\n",
            "\n",
            "back to words\n",
            "['אנרכיזם', 'אוטיזם קלאסי', 'אלבדו', 'אלבמה', 'אכילס']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59u-B03Q2FDR",
        "colab_type": "code",
        "outputId": "d38d6679-0b84-4d23-8a33-dba03aefe2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"words\")\n",
        "plt.hist(list(map(len, all_words)), bins=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('translations')\n",
        "plt.hist(list(map(len, all_translations)), bins=20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.000e+00, 3.700e+01, 1.551e+03, 2.956e+03, 2.804e+03, 3.522e+03,\n",
              "        3.953e+03, 3.953e+03, 3.935e+03, 4.696e+03, 4.754e+03, 5.073e+03,\n",
              "        5.025e+03, 4.831e+03, 4.294e+03, 3.586e+03, 3.000e+03, 2.460e+03,\n",
              "        2.019e+03, 1.657e+03]),\n",
              " array([ 1.  ,  1.95,  2.9 ,  3.85,  4.8 ,  5.75,  6.7 ,  7.65,  8.6 ,\n",
              "         9.55, 10.5 , 11.45, 12.4 , 13.35, 14.3 , 15.25, 16.2 , 17.15,\n",
              "        18.1 , 19.05, 20.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAEICAYAAACd/8f0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s0a-8ap3KfB",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: deploy encoder-decoder (1 point)\n",
        "\n",
        "seq2seq模型model提供以下接口：\n",
        "- model.symbolic_translate(inp, **flags)-> out, logp：输入为：\n",
        "- model.symbolic_score(inp, out, **flags) -> logp\n",
        "- model.weights：所有层的权重。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ402oKX2VJ9",
        "colab_type": "code",
        "outputId": "49e1bcfc-4f2b-434b-96ba-bf099cc7440d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "tf.reset_default_graph()\n",
        "s = tf.InteractiveSession()\n",
        "\n",
        "# ^^^ if you get \"variable *** already exists\": re-run this cell again"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j0begV-4587",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# This code implements a single-GRU seq2seq model. You will have to improve it later in the assignment.\n",
        "# Note 1: when using several recurrent layers TF can mixed up the weights of different recurrent layers.\n",
        "# In that case, make sure you both create AND use each rnn/gru/lstm/custom layer in a unique variable scope\n",
        "# e.g. with tf.variable_scope(\"first_lstm\"): new_cell, new_out = self.lstm_1(...)\n",
        "#      with tf.variable_scope(\"second_lstm\"): new_cell2, new_out2 = self.lstm_2(...)\n",
        "# Note 2: everything you need for decoding should be stored in model state (output list of both encode and decode)\n",
        "# e.g. for attention, you should store all encoder sequence and input mask\n",
        "# there in addition to lstm/gru states.\n",
        "\n",
        "\n",
        "class BasicTranslationModel:\n",
        "    def __init__(self, name, inp_voc, out_voc,\n",
        "                 emb_size, hid_size,):\n",
        "\n",
        "        self.name = name\n",
        "        self.inp_voc = inp_voc\n",
        "        self.out_voc = out_voc\n",
        "\n",
        "        with tf.variable_scope(name):\n",
        "            self.emb_inp = L.Embedding(len(inp_voc), emb_size)\n",
        "            self.emb_out = L.Embedding(len(out_voc), emb_size)\n",
        "            self.enc0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
        "            self.dec_start = L.Dense(hid_size)\n",
        "            self.dec0 = tf.nn.rnn_cell.GRUCell(hid_size)\n",
        "            self.logits = L.Dense(len(out_voc))\n",
        "\n",
        "            # run on dummy output to .build all layers (and therefore create\n",
        "            # weights)\n",
        "            inp = tf.placeholder('int32', [None, None])\n",
        "            out = tf.placeholder('int32', [None, None])\n",
        "            h0 = self.encode(inp)\n",
        "            h1 = self.decode(h0, out[:, 0])\n",
        "            # h2 = self.decode(h1,out[:,1]) etc.\n",
        "\n",
        "        self.weights = tf.get_collection(\n",
        "            tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\n",
        "\n",
        "    def encode(self, inp, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic input sequence, computes initial state\n",
        "        :param inp: matrix of input tokens [batch, time]\n",
        "        :return: a list of initial decoder state tensors\n",
        "        \"\"\"\n",
        "        inp_lengths = infer_length(inp, self.inp_voc.eos_ix)\n",
        "        inp_emb = self.emb_inp(inp)\n",
        "\n",
        "        _, enc_last = tf.nn.dynamic_rnn(\n",
        "            self.enc0, inp_emb,\n",
        "            sequence_length=inp_lengths,\n",
        "            dtype=inp_emb.dtype)\n",
        "\n",
        "        dec_start = self.dec_start(enc_last)\n",
        "        return [dec_start]\n",
        "\n",
        "    def decode(self, prev_state, prev_tokens, **flags):\n",
        "        \"\"\"\n",
        "        Takes previous decoder state and tokens, returns new state and logits\n",
        "        :param prev_state: a list of previous decoder state tensors\n",
        "        :param prev_tokens: previous output tokens, an int vector of [batch_size]\n",
        "        :return: a list of next decoder state tensors, a tensor of logits [batch,n_tokens]\n",
        "        \"\"\"\n",
        "\n",
        "        [prev_dec] = prev_state\n",
        "\n",
        "        prev_emb = self.emb_out(prev_tokens[:, None])[:, 0]\n",
        "\n",
        "        new_dec_out, new_dec_state = self.dec0(prev_emb, prev_dec)\n",
        "\n",
        "        output_logits = self.logits(new_dec_out)\n",
        "\n",
        "        return [new_dec_state], output_logits\n",
        "\n",
        "    def symbolic_score(self, inp, out, eps=1e-30, **flags):\n",
        "        \"\"\"\n",
        "        Takes symbolic int32 matrices of hebrew words and their english translations.\n",
        "        Computes the log-probabilities of all possible english characters given english prefices and hebrew word.\n",
        "        :param inp: input sequence, int32 matrix of shape [batch,time]\n",
        "        :param out: output sequence, int32 matrix of shape [batch,time]\n",
        "        :return: log-probabilities of all possible english characters of shape [bath,time,n_tokens]\n",
        "        NOTE: log-probabilities time axis  is synchronized with out\n",
        "        In other words, logp are probabilities of __current__ output at each tick, not the next one\n",
        "        therefore you can get likelihood as logprobas * tf.one_hot(out,n_tokens)\n",
        "        \"\"\"\n",
        "        first_state = self.encode(inp, **flags)\n",
        "\n",
        "        batch_size = tf.shape(inp)[0]\n",
        "        bos = tf.fill([batch_size], self.out_voc.bos_ix)\n",
        "        first_logits = tf.log(tf.one_hot(bos, len(self.out_voc)) + eps)\n",
        "\n",
        "        def step(blob, y_prev):\n",
        "            h_prev = blob[:-1]\n",
        "            h_new, logits = self.decode(h_prev, y_prev, **flags)\n",
        "            return list(h_new) + [logits]\n",
        "\n",
        "        results = tf.scan(step, initializer=list(first_state) + [first_logits],\n",
        "                          elems=tf.transpose(out))\n",
        "\n",
        "        # gather state and logits, each of shape [time,batch,...]\n",
        "        states_seq, logits_seq = results[:-1], results[-1]\n",
        "\n",
        "        # add initial state and logits\n",
        "        logits_seq = tf.concat((first_logits[None], logits_seq), axis=0)\n",
        "\n",
        "        # convert from [time,batch,...] to [batch,time,...]\n",
        "        logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
        "\n",
        "        return tf.nn.log_softmax(logits_seq)\n",
        "\n",
        "    def symbolic_translate(\n",
        "            self,\n",
        "            inp,\n",
        "            greedy=False,\n",
        "            max_len=None,\n",
        "            eps=1e-30,\n",
        "            **flags):\n",
        "        \"\"\"\n",
        "        takes symbolic int32 matrix of hebrew words, produces output tokens sampled\n",
        "        from the model and output log-probabilities for all possible tokens at each tick.\n",
        "        :param inp: input sequence, int32 matrix of shape [batch,time]\n",
        "        :param greedy: if greedy, takes token with highest probablity at each tick.\n",
        "            Otherwise samples proportionally to probability.\n",
        "        :param max_len: max length of output, defaults to 2 * input length\n",
        "        :return: output tokens int32[batch,time] and\n",
        "                 log-probabilities of all tokens at each tick, [batch,time,n_tokens]\n",
        "        \"\"\"\n",
        "        first_state = self.encode(inp, **flags)\n",
        "\n",
        "        batch_size = tf.shape(inp)[0]\n",
        "        bos = tf.fill([batch_size], self.out_voc.bos_ix)\n",
        "        first_logits = tf.log(tf.one_hot(bos, len(self.out_voc)) + eps)\n",
        "        max_len = tf.reduce_max(tf.shape(inp)[1]) * 2\n",
        "\n",
        "        def step(blob, t):\n",
        "            h_prev, y_prev = blob[:-2], blob[-1]\n",
        "            h_new, logits = self.decode(h_prev, y_prev, **flags)\n",
        "            y_new = (\n",
        "                tf.argmax(logits, axis=-1) if greedy\n",
        "                else tf.multinomial(logits, 1)[:, 0]\n",
        "            )\n",
        "            return list(h_new) + [logits, tf.cast(y_new, y_prev.dtype)]\n",
        "\n",
        "        results = tf.scan(\n",
        "            step,\n",
        "            initializer=list(first_state) + [first_logits, bos],\n",
        "            elems=[tf.range(max_len)],\n",
        "        )\n",
        "\n",
        "        # gather state, logits and outs, each of shape [time,batch,...]\n",
        "        states_seq, logits_seq, out_seq = (\n",
        "            results[:-2], results[-2], results[-1]\n",
        "        )\n",
        "\n",
        "        # add initial state, logits and out\n",
        "        logits_seq = tf.concat((first_logits[None], logits_seq), axis=0)\n",
        "        out_seq = tf.concat((bos[None], out_seq), axis=0)\n",
        "        states_seq = [\n",
        "            tf.concat((init[None], states), axis=0)\n",
        "            for init, states in zip(first_state, states_seq)\n",
        "        ]\n",
        "\n",
        "        # convert from [time,batch,...] to [batch,time,...]\n",
        "        logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
        "        out_seq = tf.transpose(out_seq)\n",
        "        states_seq = [\n",
        "            tf.transpose(states, [1, 0] + list(range(2, states.shape.ndims)))\n",
        "            for states in states_seq\n",
        "        ]\n",
        "\n",
        "        return out_seq, tf.nn.log_softmax(logits_seq)\n",
        "\n",
        "\n",
        "### Utility functions ###\n",
        "\n",
        "def initialize_uninitialized(sess=None):\n",
        "    \"\"\"\n",
        "    Initialize unitialized variables, doesn't affect those already initialized\n",
        "    :param sess: in which session to initialize stuff. Defaults to tf.get_default_session()\n",
        "    \"\"\"\n",
        "    sess = sess or tf.get_default_session()\n",
        "    global_vars = tf.global_variables()\n",
        "    is_not_initialized = sess.run(\n",
        "        [tf.is_variable_initialized(var) for var in global_vars]\n",
        "    )\n",
        "    not_initialized_vars = [\n",
        "        v for (v, f)\n",
        "        in zip(global_vars, is_not_initialized)\n",
        "        if not f\n",
        "    ]\n",
        "\n",
        "    if len(not_initialized_vars):\n",
        "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
        "\n",
        "\n",
        "def infer_length(seq, eos_ix, time_major=False, dtype=tf.int32):\n",
        "    \"\"\"\n",
        "    compute length given output indices and eos code\n",
        "    :param seq: tf matrix [time,batch] if time_major else [batch,time]\n",
        "    :param eos_ix: integer index of end-of-sentence token\n",
        "    :returns: lengths, int32 vector of shape [batch]\n",
        "    \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    is_eos = tf.cast(tf.equal(seq, eos_ix), dtype)\n",
        "    count_eos = tf.cumsum(is_eos, axis=axis, exclusive=True)\n",
        "    lengths = tf.reduce_sum(tf.cast(tf.equal(count_eos, 0), dtype), axis=axis)\n",
        "    return lengths\n",
        "\n",
        "\n",
        "def infer_mask(seq, eos_ix, time_major=False, dtype=tf.float32):\n",
        "    \"\"\"\n",
        "    compute mask given output indices and eos code\n",
        "    :param seq: tf matrix [time,batch] if time_major else [batch,time]\n",
        "    :param eos_ix: integer index of end-of-sentence token\n",
        "    :returns: mask, float32 matrix with '0's and '1's of same shape as seq\n",
        "    \"\"\"\n",
        "    axis = 0 if time_major else 1\n",
        "    lengths = infer_length(seq, eos_ix, time_major=time_major)\n",
        "    mask = tf.sequence_mask(lengths, maxlen=tf.shape(seq)[axis], dtype=dtype)\n",
        "    if time_major:\n",
        "        mask = tf.transpose(mask)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def select_values_over_last_axis(values, indices):\n",
        "    \"\"\"\n",
        "    Auxiliary function to select logits corresponding to chosen tokens.\n",
        "    :param values: logits for all actions: float32[batch,tick,action]\n",
        "    :param indices: action ids int32[batch,tick]\n",
        "    :returns: values selected for the given actions: float[batch,tick]\n",
        "    \"\"\"\n",
        "    assert values.shape.ndims == 3 and indices.shape.ndims == 2\n",
        "    batch_size, seq_len = tf.shape(indices)[0], tf.shape(indices)[1]\n",
        "    batch_i = tf.tile(tf.range(0, batch_size)[:, None], [1, seq_len])\n",
        "    time_i = tf.tile(tf.range(0, seq_len)[None, :], [batch_size, 1])\n",
        "    indices_nd = tf.stack([batch_i, time_i, indices], axis=-1)\n",
        "\n",
        "    return tf.gather_nd(values, indices_nd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCK4NAw548gl",
        "colab_type": "code",
        "outputId": "50309d69-ac5b-4d9c-b1ad-a8032ced9464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "model = BasicTranslationModel('model', inp_voc, out_voc,emb_size=64, hid_size=128)\n",
        "\n",
        "s.run(tf.global_variables_initializer())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-11-ccad431aefbc>:14: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From <ipython-input-11-ccad431aefbc>:42: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxkbBoAO_tu-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6L1DRZu5DEr",
        "colab_type": "code",
        "outputId": "8f9e6586-eecb-409f-c3b4-daeb75836aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# Play around with symbolic_translate and symbolic_score\n",
        "inp = tf.placeholder_with_default(np.random.randint(\n",
        "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
        "out = tf.placeholder_with_default(np.random.randint(\n",
        "    0, 10, [3, 5], dtype='int32'), [None, None])\n",
        "\n",
        "# translate inp (with untrained model)\n",
        "sampled_out, logp = model.symbolic_translate(inp, greedy=False)\n",
        "print(\"\\nSymbolic_translate output:\\n\", sampled_out, logp)\n",
        "print(\"\\nSample translations:\\n\", s.run(sampled_out))\n",
        "\n",
        "# score logp(out | inp) with untrained input\n",
        "logp = model.symbolic_score(inp, out)\n",
        "print(\"\\nSymbolic_score output:\\n\", logp)\n",
        "print(\"\\nLog-probabilities (clipped):\\n\", s.run(logp)[:, :2, :5])\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-ccad431aefbc>:130: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "\n",
            "Symbolic_translate output:\n",
            " Tensor(\"transpose_1:0\", shape=(?, ?), dtype=int32) Tensor(\"LogSoftmax:0\", shape=(?, ?, 157), dtype=float32)\n",
            "\n",
            "Sample translations:\n",
            " [[  0   9  73  49  39  61  73 153 138 100   5]\n",
            " [  0  88  96  88  18  11  72  37  72   5  84]\n",
            " [  0  36  89  95 123   5  74 107  90   5  60]]\n",
            "\n",
            "Symbolic_score output:\n",
            " Tensor(\"LogSoftmax_1:0\", shape=(?, ?, 157), dtype=float32)\n",
            "\n",
            "Log-probabilities (clipped):\n",
            " [[[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -5.0608993  -5.0602784  -5.0495543  -5.064661   -5.054993 ]]\n",
            "\n",
            " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -5.0579967  -5.051896   -5.049721   -5.0641327  -5.0486627]]\n",
            "\n",
            " [[  0.        -69.07755   -69.07755   -69.07755   -69.07755  ]\n",
            "  [ -5.059315   -5.0587687  -5.055589   -5.0386596  -5.054118 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckx5mX165OpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare any operations you want here\n",
        "input_sequence = tf.placeholder('int32', [None, None])\n",
        "greedy_translations, logp = model.symbolic_translate(input_sequence, greedy=True)\n",
        "\n",
        "\n",
        "def translate(lines):\n",
        "    \"\"\"\n",
        "    You are given a list of input lines. \n",
        "    Make your neural network translate them.\n",
        "    :return: a list of output lines\n",
        "    \"\"\"\n",
        "    # Convert lines to a matrix of indices\n",
        "    lines_ix = inp_voc.to_matrix(lines)\n",
        "    print(\"lines_ix shape={}\".format(lines_ix.shape))\n",
        "\n",
        "    # Compute translations in form of indices\n",
        "    trans_ix = s.run(greedy_translations, {input_sequence:lines_ix})\n",
        "\n",
        "    # Convert translations back into strings\n",
        "    return out_voc.to_lines(trans_ix)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLbPm9mG5bDj",
        "colab_type": "code",
        "outputId": "9bcc105b-bbb4-4fc1-d255-7941af4d3dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(\"Sample inputs:\", all_words[:3])\n",
        "print(\"Dummy translations:\", translate(all_words[:3]))\n",
        "\n",
        "assert isinstance(greedy_translations,\n",
        "                  tf.Tensor) and greedy_translations.dtype.is_integer, \"trans must be a tensor of integers (token ids)\"\n",
        "assert translate(all_words[:3]) == translate(\n",
        "    all_words[:3]), \"make sure translation is deterministic (use greedy=True and disable any noise layers)\"\n",
        "assert type(translate(all_words[:3])) is list and (type(translate(all_words[:1])[0]) is str or type(\n",
        "    translate(all_words[:1])[0]) is unicode), \"translate(lines) must return a sequence of strings!\"\n",
        "print(\"Tests passed!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample inputs: ['אנרכיזם' 'אוטיזם קלאסי' 'אלבדו']\n",
            "lines_ix shape=(3, 14)\n",
            "Dummy translations: ['ě00üנäấůůůůůůůůůůůůůůטůůůůůů', 'y``̇ʻňêêêîêêø***șșkÿ(ssאìṇìâ', 'ě!ș']\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(3, 14)\n",
            "lines_ix shape=(1, 9)\n",
            "Tests passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmb_E_hdaHTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 打分函数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U1ATUqRaC-e",
        "colab_type": "code",
        "outputId": "8bb677f9-4857-4b88-915c-4a07ac60bc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install editdistance\n",
        "import editdistance  # !pip install editdistance\n",
        "\n",
        "\n",
        "def get_distance(word, trans):\n",
        "    \"\"\"\n",
        "    A function that takes word and predicted translation\n",
        "    and evaluates (Levenshtein's) edit distance to closest correct translation\n",
        "    \"\"\"\n",
        "    references = word_to_translation[word]\n",
        "    assert len(references) != 0, \"wrong/unknown word\"\n",
        "    return min(editdistance.eval(trans, ref) for ref in references)\n",
        "\n",
        "\n",
        "def score(words, bsize=100):\n",
        "    \"\"\"a function that computes levenshtein distance for bsize random samples\"\"\"\n",
        "    assert isinstance(words, np.ndarray)\n",
        "\n",
        "    batch_words = np.random.choice(words, size=bsize, replace=False)\n",
        "    batch_trans = translate(batch_words)\n",
        "\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "\n",
        "    return np.array(distances, dtype='float32')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFfU773QaNZ6",
        "colab_type": "code",
        "outputId": "4d992197-3999-48c6-9c08-dbb05ad1db1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "[score(test_words, 10).mean() for _ in range(5)]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(10, 22)\n",
            "lines_ix shape=(10, 22)\n",
            "lines_ix shape=(10, 22)\n",
            "lines_ix shape=(10, 20)\n",
            "lines_ix shape=(10, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[36.0, 43.7, 40.9, 36.5, 40.3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adu6CLgHaWjO",
        "colab_type": "text"
      },
      "source": [
        "### 开始训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEKkRyRaVza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import utility functions\n",
        "#from basic_model_tf import initialize_uninitialized, infer_length, infer_mask, select_values_over_last_axis\n",
        "\n",
        "\n",
        "class supervised_training:\n",
        "\n",
        "    # variable for inputs and correct answers\n",
        "    input_sequence = tf.placeholder('int32', [None, None])\n",
        "    reference_answers = tf.placeholder('int32', [None, None])\n",
        "\n",
        "    # Compute log-probabilities of all possible tokens at each step. Use model interface.\n",
        "    logprobs_seq = model.symbolic_score(input_sequence, reference_answers)\n",
        "\n",
        "    # compute mean crossentropy\n",
        "    crossentropy = - select_values_over_last_axis(logprobs_seq, reference_answers)\n",
        "\n",
        "    mask = infer_mask(reference_answers, out_voc.eos_ix)\n",
        "\n",
        "    loss = tf.reduce_sum(crossentropy * mask)/tf.reduce_sum(mask)\n",
        "\n",
        "    # Build weights optimizer. Use model.weights to get all trainable params.\n",
        "    train_step = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "\n",
        "# intialize optimizer params while keeping model intact\n",
        "initialize_uninitialized(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2njBSnaRM8",
        "colab_type": "code",
        "outputId": "92796456-5a3c-4eaf-d89f-2a306f8ade74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def sample_batch(words, word_to_translation, batch_size):\n",
        "    \"\"\"\n",
        "    sample random batch of words and random correct translation for each word\n",
        "    example usage:\n",
        "    batch_x,batch_y = sample_batch(train_words, word_to_translations,10)\n",
        "    \"\"\"\n",
        "    # choose words\n",
        "    batch_words = np.random.choice(words, size=batch_size)\n",
        "\n",
        "    # choose translations\n",
        "    batch_trans_candidates = list(map(word_to_translation.get, batch_words))\n",
        "    batch_trans = list(map(random.choice, batch_trans_candidates))\n",
        "\n",
        "    return inp_voc.to_matrix(batch_words), out_voc.to_matrix(batch_trans)\n",
        "    \n",
        "bx, by = sample_batch(train_words, word_to_translation, batch_size=3)\n",
        "print(\"Source:\")\n",
        "print(bx)\n",
        "print(\"Target:\")\n",
        "print(by)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source:\n",
            "[[ 0  8 41  5  8 41 21 46 40 83 41 70 30 10  1  1]\n",
            " [ 0  6 38  5 30  9 21  8  5 46 13 63 70 13  7  1]\n",
            " [ 0 27 10  5 27 48  6 10  7  1  1  1  1  1  1  1]]\n",
            "Target:\n",
            "[[  0 101  96  94  41 101  30  17  94  98  27 151  29  73 101  18   3   1\n",
            "    1   1   1]\n",
            " [  0   3  29  84  30   3  18  96  27  29 137  27 131  18 101   3  94  30\n",
            "   23 101   1]\n",
            " [  0   3 101  98  18   3 101  39  84  98  94   1   1   1   1   1   1   1\n",
            "    1   1   1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QU7Jp9Yaseu",
        "colab_type": "code",
        "outputId": "bcaa921b-09e6-43b0-fb12-7fab4842992d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange  # or use tqdm_notebook,tnrange\n",
        "\n",
        "loss_history = []\n",
        "editdist_history = []\n",
        "\n",
        "for i in trange(25000):\n",
        "    bx, by = sample_batch(train_words, word_to_translation, 32)\n",
        "\n",
        "    feed_dict = {\n",
        "        supervised_training.input_sequence: bx,\n",
        "        supervised_training.reference_answers: by\n",
        "    }\n",
        "\n",
        "    loss, _ = s.run([supervised_training.loss,\n",
        "                     supervised_training.train_step], feed_dict)\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    if (i+1) % REPORT_FREQ == 0:\n",
        "        clear_output(True)\n",
        "        current_scores = score(test_words)\n",
        "        editdist_history.append(current_scores.mean())\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(131)\n",
        "        plt.title('train loss / traning time')\n",
        "        plt.plot(loss_history)\n",
        "        plt.grid()\n",
        "        plt.subplot(132)\n",
        "        plt.title('val score distribution')\n",
        "        plt.hist(current_scores, bins=20)\n",
        "        plt.subplot(133)\n",
        "        plt.title('val score / traning time')\n",
        "        plt.plot(editdist_history)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        print(\"llh=%.3f, mean score=%.3f\" %\n",
        "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))\n",
        "\n",
        "# Note: it's okay if loss oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(100, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAEICAYAAACwF1f6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 25000/25000 [28:56<00:00, 14.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "llh=1.279, mean score=6.946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpTUM6v6avXQ",
        "colab_type": "code",
        "outputId": "0260cc6f-905d-401a-c505-d733092e7786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for word in train_words[:10]:\n",
        "    print(\"%s -> %s\" % (word, translate([word])[0]))\n",
        "\n",
        "test_scores = []\n",
        "for start_i in trange(0, len(test_words), 32):\n",
        "    batch_words = test_words[start_i:start_i+32]\n",
        "    batch_trans = translate(batch_words)\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "    test_scores.extend(distances)\n",
        "\n",
        "print(\"Supervised test score:\", np.mean(test_scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(1, 16)\n",
            "כל אנשי סמיילי -> cassian mallians\n",
            "lines_ix shape=(1, 16)\n",
            "קטגוריה:ערוץ 2 -> 20\n",
            "lines_ix shape=(1, 13)\n",
            "עבודה מהבית -> abbat hamorica\n",
            "lines_ix shape=(1, 8)\n",
            "פראליה -> pralia\n",
            "lines_ix shape=(1, 9)\n",
            "קפלר 42 -> cappell 24\n",
            "lines_ix shape=(1, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/407 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "קטגוריה:מתאסלמים -> mathamslim\n",
            "lines_ix shape=(1, 7)\n",
            "בושמי -> boshmi\n",
            "lines_ix shape=(1, 9)\n",
            "לאונרדו -> laundrou\n",
            "lines_ix shape=(1, 6)\n",
            "שאמה -> shama\n",
            "lines_ix shape=(1, 7)\n",
            "עכברה -> achabara\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 4/407 [00:00<00:23, 17.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 17)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 8/407 [00:00<00:23, 17.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 12/407 [00:00<00:24, 16.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 16/407 [00:00<00:24, 15.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▍         | 20/407 [00:01<00:24, 16.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 24/407 [00:01<00:23, 15.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 28/407 [00:01<00:23, 16.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 17)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 32/407 [00:01<00:22, 16.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 18)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 36/407 [00:02<00:22, 16.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|▉         | 40/407 [00:02<00:22, 16.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 44/407 [00:02<00:22, 16.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 48/407 [00:02<00:21, 16.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 52/407 [00:03<00:21, 16.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 56/407 [00:03<00:20, 17.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 60/407 [00:03<00:20, 17.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 18)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 64/407 [00:03<00:20, 16.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 68/407 [00:04<00:20, 16.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 72/407 [00:04<00:20, 16.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 76/407 [00:04<00:20, 16.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 80/407 [00:04<00:19, 16.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 84/407 [00:05<00:19, 16.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 88/407 [00:05<00:19, 16.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 18)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 92/407 [00:05<00:18, 16.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 96/407 [00:05<00:18, 16.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 100/407 [00:06<00:18, 16.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 105/407 [00:06<00:16, 17.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 16)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 17)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 109/407 [00:06<00:16, 17.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 113/407 [00:06<00:17, 16.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 117/407 [00:07<00:17, 16.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 121/407 [00:07<00:16, 17.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|███       | 125/407 [00:07<00:16, 17.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 129/407 [00:07<00:16, 17.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 133/407 [00:07<00:16, 16.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|███▎      | 137/407 [00:08<00:15, 17.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 141/407 [00:08<00:15, 17.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 17)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 145/407 [00:08<00:14, 17.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 149/407 [00:08<00:14, 17.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 153/407 [00:09<00:14, 17.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 157/407 [00:09<00:14, 17.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 161/407 [00:09<00:14, 17.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|████      | 165/407 [00:09<00:14, 17.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 169/407 [00:10<00:13, 17.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 173/407 [00:10<00:13, 17.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 177/407 [00:10<00:13, 17.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 181/407 [00:10<00:13, 17.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 185/407 [00:10<00:13, 16.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 189/407 [00:11<00:12, 16.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 193/407 [00:11<00:12, 16.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 197/407 [00:11<00:12, 16.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 16)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 201/407 [00:11<00:12, 16.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 205/407 [00:12<00:12, 16.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 209/407 [00:12<00:11, 17.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 213/407 [00:12<00:11, 17.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 218/407 [00:12<00:11, 16.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 222/407 [00:13<00:10, 17.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 226/407 [00:13<00:10, 17.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 230/407 [00:13<00:10, 17.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 234/407 [00:13<00:09, 17.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 238/407 [00:14<00:10, 16.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 242/407 [00:14<00:09, 17.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 246/407 [00:14<00:09, 16.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 250/407 [00:14<00:09, 17.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 254/407 [00:15<00:09, 16.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 258/407 [00:15<00:08, 16.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 262/407 [00:15<00:08, 16.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 266/407 [00:15<00:08, 16.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▋   | 270/407 [00:16<00:08, 16.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 274/407 [00:16<00:08, 16.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 278/407 [00:16<00:07, 16.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 282/407 [00:16<00:07, 16.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 286/407 [00:16<00:07, 17.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 290/407 [00:17<00:07, 16.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 294/407 [00:17<00:06, 16.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 298/407 [00:17<00:06, 15.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 302/407 [00:17<00:06, 16.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 306/407 [00:18<00:06, 16.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 310/407 [00:18<00:05, 16.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 314/407 [00:18<00:05, 16.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 318/407 [00:18<00:05, 16.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 322/407 [00:19<00:05, 16.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 18)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 326/407 [00:19<00:04, 16.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 330/407 [00:19<00:04, 16.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 334/407 [00:19<00:04, 16.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 15)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 338/407 [00:20<00:04, 16.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 342/407 [00:20<00:03, 16.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 346/407 [00:20<00:03, 16.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 350/407 [00:20<00:03, 16.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 354/407 [00:21<00:03, 16.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 358/407 [00:21<00:03, 16.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 362/407 [00:21<00:02, 16.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 366/407 [00:21<00:02, 17.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 370/407 [00:22<00:02, 17.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 374/407 [00:22<00:01, 17.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 18)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 378/407 [00:22<00:01, 17.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 17)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 382/407 [00:22<00:01, 16.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 386/407 [00:23<00:01, 16.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 390/407 [00:23<00:01, 16.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 19)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 394/407 [00:23<00:00, 16.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 398/407 [00:23<00:00, 16.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 402/407 [00:24<00:00, 16.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(32, 20)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 406/407 [00:24<00:00, 16.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lines_ix shape=(32, 22)\n",
            "lines_ix shape=(32, 20)\n",
            "lines_ix shape=(32, 21)\n",
            "lines_ix shape=(20, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 407/407 [00:24<00:00, 16.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Supervised test score: 6.713495235167538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWG4okZgeu21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQrTTe7njmcY",
        "colab_type": "text"
      },
      "source": [
        "### 自定义损失函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyz9hoHMn7J-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d2ac350-342f-405a-d13e-f6415f8194b4"
      },
      "source": [
        "editdistance.eval('abc', 'cde')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RiSaduqYcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa648a6-29e5-42f4-d0ef-502a15c3bf8b"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '_'), (1, ';')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBBaRAbkkIw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_ix_to_token = dict([(v,k) for k, v in inp_voc.token_to_ix.items()])\n",
        "trans_ix_to_token = dict([v,k] for k, v in out_voc.token_to_ix.items())\n",
        "def _compute_levenshtein(words_ix, trans_ix):\n",
        "    \"\"\"\n",
        "    A custom tensorflow operation that computes levenshtein loss for predicted trans.\n",
        "\n",
        "    Params:\n",
        "    - words_ix - a matrix of letter indices, shape=[batch_size,word_length]\n",
        "    - words_mask - a matrix of zeros/ones, \n",
        "       1 means \"word is still not finished\"\n",
        "       0 means \"word has already finished and this is padding\"\n",
        "\n",
        "    - trans_mask - a matrix of output letter indices, shape=[batch_size,translation_length]\n",
        "    - trans_mask - a matrix of zeros/ones, similar to words_mask but for trans_ix\n",
        "\n",
        "\n",
        "    Please implement the function and make sure it passes tests from the next cell.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # convert words to strings\n",
        "    words = [[words_ix_to_token[w] for w in word] for word in words_ix]\n",
        "    words = [\"\".join(word) for word in words]\n",
        "\n",
        "    assert type(words) is list and type(\n",
        "        words[0]) is str and len(words) == len(words_ix)\n",
        "\n",
        "    # convert translations to lists\n",
        "    translations = [[trans_ix_to_token[t] for t in tran] for tran in trans_ix]\n",
        "    translations=[\"\".join(tran) for tran in translations]\n",
        "    #print(translations[0])\n",
        "\n",
        "    assert type(translations) is list and type(\n",
        "        translations[0]) is str and len(translations) == len(trans_ix)\n",
        "\n",
        "    # computes levenstein distances. can be arbitrary python code.\n",
        "    distances = [editdistance.eval(w, t) for w, t in zip(words, translations)]\n",
        "\n",
        "    assert type(distances) in (list, tuple, np.ndarray) and len(\n",
        "        distances) == len(words_ix)\n",
        "\n",
        "    distances = np.array(list(distances), dtype='float32')\n",
        "    return distances\n",
        "\n",
        "def compute_levenshtein(words_ix, trans_ix):\n",
        "    out = tf.py_func(_compute_levenshtein, [words_ix, trans_ix, ], tf.float32)\n",
        "    out.set_shape([None])\n",
        "\n",
        "    return tf.stop_gradient(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgF-I-0mp0HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQIItqBk3DI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "1161ba97-bd82-4fd3-d3fd-cab65123c02a"
      },
      "source": [
        "# 测试上面代码\n",
        "# test suite\n",
        "# sample random batch of (words, correct trans, wrong trans)\n",
        "batch_words = np.random.choice(train_words, size=100)\n",
        "\n",
        "batch_trans = list(map(random.choice, map(\n",
        "    word_to_translation.get, batch_words)))\n",
        "batch_trans_wrong = np.random.choice(all_translations, size=100)\n",
        "\n",
        "batch_words_ix = tf.constant(inp_voc.to_matrix(batch_words))\n",
        "batch_trans_ix = tf.constant(out_voc.to_matrix(batch_trans))\n",
        "batch_trans_wrong_ix = tf.constant(out_voc.to_matrix(batch_trans_wrong))\n",
        "\n",
        "# assert compute_levenshtein is zero for ideal translations\n",
        "correct_answers_score = compute_levenshtein(\n",
        "    batch_words_ix, batch_trans_ix).eval()\n",
        "print(\"score={}\".format(correct_answers_score))\n",
        "#assert np.all(correct_answers_score ==0), \"a perfect translation got nonzero levenshtein score!\"\n",
        "\n",
        "print(\"Everything seems alright!\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score=[19. 16.  8. 19. 12.  9. 11.  9.  8. 19. 13.  5. 17. 17.  0. 16. 19.  9.\n",
            " 12.  9. 11. 14.  8. 20. 12. 14. 13. 16.  7. 13.  7. 17. 16. 13. 13.  8.\n",
            " 11. 12.  9. 20. 13.  7. 16. 14. 14. 11. 19. 18.  9. 19. 12. 11.  9. 14.\n",
            "  5.  0. 12. 19. 12.  5.  6.  6. 16. 13. 20. 13. 19. 18. 14.  7. 18.  9.\n",
            " 14.  8.  5.  9.  9.  5. 12.  4. 15. 14.  0. 17.  0. 14. 16. 14.  9. 14.\n",
            "  8.  9. 11. 12.  5.  7.  0. 11.  4. 16.]\n",
            "Everything seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb43aEjYot9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iNrSX4r3QL",
        "colab_type": "text"
      },
      "source": [
        "### self-critical policy gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yecBY47tsMkb",
        "colab_type": "text"
      },
      "source": [
        "实现 self-critical sequence training.[论文](https://arxiv.org/abs/1612.00563)\n",
        "\n",
        "The algorithm is a vanilla policy gradient with a special baseline.\n",
        "\n",
        "$$ \\nabla J = E_{x \\sim p(s)} E_{y \\sim \\pi(y|x)} \\nabla log \\pi(y|x) \\cdot (R(x,y) - b(x)) $$\n",
        "Here reward R(x,y) is a negative levenshtein distance (since we minimize it). The baseline b(x) represents how well model fares on word x.\n",
        "\n",
        "In practice, this means that we compute baseline as a score of greedy translation, $b(x) = R(x,y_{greedy}(x)) $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HHu9aYcr9AB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class trainer:\n",
        "\n",
        "    input_sequence = tf.placeholder('int32', [None, None])\n",
        "\n",
        "    # use model to __sample__ symbolic translations given input_sequence\n",
        "    sample_translations, sample_logp = <YOUR CODE >\n",
        "    # use model to __greedy__ symbolic translations given input_sequence\n",
        "    greedy_translations, greedy_logp = <YOUR CODE >\n",
        "\n",
        "    rewards = - compute_levenshtein(input_sequence, sample_translations)\n",
        "\n",
        "    # compute __negative__ levenshtein for greedy mode\n",
        "    baseline = <YOUR CODE >\n",
        "\n",
        "    # compute advantage using rewards and baseline\n",
        "    advantage = <your code - compute advantage >\n",
        "    assert advantage.shape.ndims == 1, \"advantage must be of shape [batch_size]\"\n",
        "\n",
        "    # compute log_pi(a_t|s_t), shape = [batch, seq_length]\n",
        "    logprobs_phoneme = # YOUR CODE\n",
        "    # ^-- hint: look at how crossentropy is implemented in supervised learning loss above\n",
        "    # mind the sign - this one should not be multiplied by -1 :)\n",
        "\n",
        "\n",
        "    # Compute policy gradient\n",
        "    # or rather surrogate function who's gradient is policy gradient\n",
        "    J = logprobs_phoneme*advantage[:, None]\n",
        "\n",
        "    mask = infer_mask(sample_translations, out_voc.eos_ix)\n",
        "    loss = - tf.reduce_sum(J*mask) / tf.reduce_sum(mask)\n",
        "\n",
        "    # regularize with negative entropy. Don't forget the sign!\n",
        "    # note: for entropy you need probabilities for all tokens (sample_logp), not just phoneme_logprobs\n",
        "    entropy = <compute entropy matrix of shape[batch, seq_length], H = -sum(p*log_p), don't forget the sign!>\n",
        "    # hint: you can get sample probabilities from sample_logp using math :)\n",
        "\n",
        "\n",
        "    assert entropy.shape.ndims == 2, \"please make sure elementwise entropy is of shape [batch,time]\"\n",
        "\n",
        "    loss -= 0.01*tf.reduce_sum(entropy*mask) / tf.reduce_sum(mask)\n",
        "\n",
        "    # compute weight updates, clip by norm\n",
        "    grads = tf.gradients(loss, model.weights)\n",
        "    grads = tf.clip_by_global_norm(grads, 50)[0]\n",
        "\n",
        "    train_step = tf.train.AdamOptimizer(\n",
        "        learning_rate=1e-5).apply_gradients(zip(grads, model.weights,))\n",
        "\n",
        "\n",
        "initialize_uninitialized()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9iuxCm1tNc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in trange(100000):\n",
        "    bx = sample_batch(train_words, word_to_translation, 32)[0]\n",
        "    pseudo_loss, _ = s.run([trainer.loss, trainer.train_step], {\n",
        "                           trainer.input_sequence: bx})\n",
        "\n",
        "    loss_history.append(\n",
        "        pseudo_loss\n",
        "    )\n",
        "\n",
        "    if (i+1) % REPORT_FREQ == 0:\n",
        "        clear_output(True)\n",
        "        current_scores = score(test_words)\n",
        "        editdist_history.append(current_scores.mean())\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.subplot(121)\n",
        "        plt.title('val score distribution')\n",
        "        plt.hist(current_scores, bins=20)\n",
        "        plt.subplot(122)\n",
        "        plt.title('val score / traning time')\n",
        "        plt.plot(editdist_history)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        print(\"J=%.3f, mean score=%.3f\" %\n",
        "              (np.mean(loss_history[-10:]), np.mean(editdist_history[-10:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5xg4sH5tQsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 测试\n",
        "for word in train_words[:10]:\n",
        "    print(\"%s -> %s\" % (word, translate([word])[0]))\n",
        "\n",
        "test_scores = []\n",
        "for start_i in trange(0, len(test_words), 32):\n",
        "    batch_words = test_words[start_i:start_i+32]\n",
        "    batch_trans = translate(batch_words)\n",
        "    distances = list(map(get_distance, batch_words, batch_trans))\n",
        "    test_scores.extend(distances)\n",
        "print(\"Supervised test score:\", np.mean(test_scores))\n",
        "\n",
        "# ^^ If you get Out Of Memory, please replace this with batched computation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66zxpiYtiTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KII4datjAB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Step 6: Make it actually work (5++ pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmjyGpsmsl1N",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/do_something_scst.png width=400>\n",
        "\n",
        "In this section we want you to finally __restart with EASY_MODE=False__ and experiment to find a good model/curriculum for that task.\n",
        "\n",
        "We recommend you to start with the following architecture\n",
        "\n",
        "```\n",
        "encoder---decoder\n",
        "\n",
        "           P(y|h)\n",
        "             ^\n",
        " LSTM  ->   LSTM\n",
        "  ^          ^\n",
        " biLSTM  ->   LSTM\n",
        "  ^          ^\n",
        "input       y_prev\n",
        "```\n",
        "\n",
        "__Note:__ you can fit all 4 state tensors of both LSTMs into a in a single state - just assume that it contains, for example, [h0, c0, h1, c1] - pack it in encode and update in decode.\n",
        "\n",
        "Here are some cool ideas on what you can do then.\n",
        "\n",
        "__General tips & tricks:__\n",
        "* In some tensorflow versions and for some layers, it is required that each rnn/gru/lstm cell gets it's own `tf.variable_scope(unique_name, reuse=False)`.\n",
        "  * Otherwise it will complain about wrong tensor sizes because it tries to reuse weights from one rnn to the other.\n",
        "* You will likely need to adjust pre-training time for such a network.\n",
        "* Supervised pre-training may benefit from clipping gradients somehow.\n",
        "* SCST may indulge a higher learning rate in some cases and changing entropy regularizer over time.\n",
        "* It's often useful to save pre-trained model parameters to not re-train it every time you want new policy gradient parameters. \n",
        "* When leaving training for nighttime, try setting REPORT_FREQ to a larger value (e.g. 500) not to waste time on it.\n",
        "\n",
        "\n",
        "\n",
        "__Formal criteria:__\n",
        "To get 5 points we want you to build an architecture that:\n",
        "* _doesn't consist of single GRU_\n",
        "* _works better_ than single GRU baseline. \n",
        "* We also want you to provide either learning curve or trained model, preferably both\n",
        "* ... and write a brief report or experiment log describing what you did and how it fared.\n",
        "\n",
        "### Attention\n",
        "There's more than one way to connect decoder to encoder\n",
        "  * __Vanilla:__ layer_i of encoder last state goes to layer_i of decoder initial state\n",
        "  * __Every tick:__ feed encoder last state _on every iteration_ of decoder.\n",
        "  * __Attention:__ allow decoder to \"peek\" at one (or several) positions of encoded sequence on every tick.\n",
        "    \n",
        "The most effective (and cool) of those is, of course, attention.\n",
        "You can read more about attention [in this nice blog post](https://distill.pub/2016/augmented-rnns/). The easiest way to begin is to use \"soft\" attention with \"additive\" or \"dot-product\" intermediate layers.\n",
        "\n",
        "__Tips__\n",
        "* Model usually generalizes better if you no longer allow decoder to see final encoder state\n",
        "* Once your model made it through several epochs, it is a good idea to visualize attention maps to understand what your model has actually learned\n",
        "\n",
        "* There's more stuff [here](https://github.com/yandexdataschool/Practical_RL/blob/master/week8_scst/bonus.ipynb)\n",
        "* If you opted for hard attention, we recommend [gumbel-softmax](https://blog.evjang.com/2016/11/tutorial-categorical-variational.html) instead of sampling. Also please make sure soft attention works fine before you switch to hard.\n",
        "\n",
        "\n",
        "### UREX\n",
        "* This is a way to improve exploration in policy-based settings. The main idea is that you find and upweight under-appreciated actions.\n",
        "* Here's [video](https://www.youtube.com/watch?v=fZNyHoXgV7M&feature=youtu.be&t=3444)\n",
        " and an [article](https://arxiv.org/abs/1611.09321).\n",
        "* You may want to reduce batch size 'cuz UREX requires you to sample multiple times per source sentence.\n",
        "* Once you got it working, try using experience replay with importance sampling instead of (in addition to) basic UREX.\n",
        "\n",
        "### Some additional ideas:\n",
        "* (advanced deep learning) It may be a good idea to first train on small phrases and then adapt to larger ones (a.k.a. training curriculum).\n",
        "* (advanced nlp) You may want to switch from raw utf8 to something like unicode or even syllables to make task easier.\n",
        "* (advanced nlp) Since hebrew words are written __with vowels omitted__, you may want to use a small Hebrew vowel markup dataset at `he-pron-wiktionary.txt`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-olFslBuRap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}