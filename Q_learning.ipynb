{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/450586509/CS234/blob/master/Q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elsuRZIJGDxG",
        "colab_type": "text"
      },
      "source": [
        "## Q-learning (3 points)\n",
        "\n",
        "This notebook will guide you through implementation of vanilla Q-learning algorithm.\n",
        "\n",
        "You need to implement QLearningAgent (follow instructions for each method) and use it on a number of tests below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqIo1e8PG6Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGA8pBSTHBI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JszMaFzsGDxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "fc1b6952-f9b6-4c34-8ece-bd840be11937"
      },
      "source": [
        "# In google collab, uncomment this:\n",
        "!wget https://bit.ly/2FMJP5K -q -O setup.py\n",
        "!bash setup.py 2>&1 1>stdout.log | tee stderr.log\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-11 12:15:30--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640 [text/plain]\n",
            "Saving to: ‘../xvfb’\n",
            "\n",
            "     0K                                                       100%  108M=0s\n",
            "\n",
            "2019-09-11 12:15:30 (108 MB/s) - ‘../xvfb’ saved [640/640]\n",
            "\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF34kLzQGDxQ",
        "colab_type": "code",
        "outputId": "3576ead7-2f48-4220-fac1-b4be9e0ecf27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile qlearning.py\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        action_value_dict = self._qvalues[state]\n",
        "        max_value = -100\n",
        "        for action, value in action_value_dict.items():\n",
        "            if value > max_value:\n",
        "                max_value = value\n",
        "\n",
        "        return max_value\n",
        "\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        nextState = next_state\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        \n",
        "\n",
        "        qsa = self._qvalues[state][action]\n",
        "        #print(\"nextState={0}\".format(nextState))\n",
        "        # all nextState\n",
        "        state_value = self.get_value(state)\n",
        "        updated_qvalue = (1-learning_rate)*qsa + learning_rate*(reward + gamma*state_value)\n",
        "        # (state, action, value)\n",
        "        self.set_qvalue(state, action, updated_qvalue)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "        best_action = None\n",
        "        action_value_dict = self._qvalues[state]\n",
        "        #print(\"action_value_dict={0}\".format(action_value_dict))\n",
        "        max_value = -100\n",
        "        for action, value in action_value_dict.items():\n",
        "            #print(\"action={0}\\tvalue={0}\".format(action, value))\n",
        "            if value > max_value:\n",
        "                max_value = value\n",
        "                best_action = action\n",
        "        #print(\"get policy best action = {0}\".format(best_action))\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        possibleActions = possible_actions\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        best_action = self.getPolicy(state=state)\n",
        "        vals = random.choices([1, 2], k=1, weights=[epsilon, 1-epsilon])\n",
        "        #print(\"epsilon={0}\\tval={1}\".format(epsilon, vals[0]))\n",
        "        if vals[0] == 1:\n",
        "            action = random.choice(possibleActions)\n",
        "        else:\n",
        "            #print(\"get action by policy\")\n",
        "            action = best_action\n",
        "        #print(\"chosen action={0}\".format(action))\n",
        "\n",
        "        return action\n",
        "    \n",
        "    def getPolicy(self, state):\n",
        "        \"\"\"\n",
        "          Compute the best action to take in a state. \n",
        "\n",
        "        \"\"\"\n",
        "        possibleActions = self.get_legal_actions(state)\n",
        "        #print(\"possibleActions={0}\".format(possibleActions))\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possibleActions) == 0:\n",
        "            return None\n",
        "\n",
        "        best_action = None\n",
        "\n",
        "        \"*** YOUR CODE HERE ***\"\n",
        "        max_value = -100\n",
        "        best_action = None\n",
        "        for action in possibleActions:\n",
        "            if self._qvalues[state][action] >= max_value:\n",
        "                max_value = self._qvalues[state][action]\n",
        "                best_action = action\n",
        "                \n",
        "        return best_action\n",
        "      \n",
        "        \n",
        "      "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing qlearning.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0NjfBz-GDxY",
        "colab_type": "text"
      },
      "source": [
        "### Try it on taxi\n",
        "\n",
        "Here we use the qlearning agent on taxi env from openai gym.\n",
        "You will need to insert a few agent functions here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YZEIiSjGDxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "env = gym.make(\"Taxi-v2\")\n",
        "\n",
        "n_actions = env.action_space.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsNMhrg9GDxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from qlearning import QLearningAgent\n",
        "\n",
        "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                       get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH4mxWHgGDxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent's e-greedy policy\n",
        "    - train agent using agent.update(...) whenever it is possible\n",
        "    - return total reward\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s.\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # train (update) agent for state s\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWFd-YJMGDxm",
        "colab_type": "code",
        "outputId": "3362b101-dcd3-4e99-b227-7b1494fbb84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "    agent.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eps = 2.9191091959171894e-05 mean reward = -209.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8NRE+vR4BvAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_UDKLdeGDxs",
        "colab_type": "text"
      },
      "source": [
        "# Binarized state spaces\n",
        "\n",
        "Use agent to train efficiently on CartPole-v0.\n",
        "This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
        "\n",
        "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
        "\n",
        "The tricky part is to get the n_digits right for each state to train effectively.\n",
        "\n",
        "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79qoEBI8GDxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"first state:%s\" % (env.reset()))\n",
        "plt.imshow(env.render('rgb_array'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfW8DHChGDxy",
        "colab_type": "text"
      },
      "source": [
        "### Play a few games\n",
        "\n",
        "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAEAcIkcGDxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_states = []\n",
        "for _ in range(1000):\n",
        "    all_states.append(env.reset())\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, done, _ = env.step(env.action_space.sample())\n",
        "        all_states.append(s)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "all_states = np.array(all_states)\n",
        "\n",
        "for obs_i in range(env.observation_space.shape[0]):\n",
        "    plt.hist(all_states[:, obs_i], bins=20)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VL4VaRSGDx5",
        "colab_type": "text"
      },
      "source": [
        "## Binarize environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLQRqIi7GDx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gym.core import ObservationWrapper\n",
        "\n",
        "\n",
        "class Binarizer(ObservationWrapper):\n",
        "\n",
        "    def observation(self, state):\n",
        "\n",
        "        # state = <round state to some amount digits.>\n",
        "        # hint: you can do that with round(x,n_digits)\n",
        "        # you will need to pick a different n_digits for each dimension\n",
        "\n",
        "        return tuple(state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJnXxmq5GDyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = Binarizer(gym.make(\"CartPole-v0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWywRC-NGDyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_states = []\n",
        "for _ in range(1000):\n",
        "    all_states.append(env.reset())\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, done, _ = env.step(env.action_space.sample())\n",
        "        all_states.append(s)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "all_states = np.array(all_states)\n",
        "\n",
        "for obs_i in range(env.observation_space.shape[0]):\n",
        "\n",
        "    plt.hist(all_states[:, obs_i], bins=20)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BFQH4VVGDyK",
        "colab_type": "text"
      },
      "source": [
        "## Learn binarized policy\n",
        "\n",
        "Now let's train a policy that uses binarized state space.\n",
        "\n",
        "__Tips:__ \n",
        "* If your binarization is too coarse, your agent may fail to find optimal policy. In that case, change binarization. \n",
        "* If your binarization is too fine-grained, your agent will take much longer than 1000 steps to converge. You can either increase number of iterations and decrease epsilon decay or change binarization.\n",
        "* Having 10^3 ~ 10^4 distinct states is recommended (`len(QLearningAgent._qvalues)`), but not required.\n",
        "* A reasonable agent should get to an average reward of >=50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um31lj94GDyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                       get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBBSr2ddGDyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "\n",
        "    # OPTIONAL YOUR CODE: adjust epsilon\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}