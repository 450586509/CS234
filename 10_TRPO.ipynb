{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_TRPO.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/450586509/reinforcement-learning-practice/blob/master/10_TRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peKTEYXZzALO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efbc1813-4c36-4299-8bf0-020bb45596aa"
      },
      "source": [
        "# # in google colab uncomment this\n",
        "\n",
        "import os\n",
        "\n",
        "os.system('apt-get install -y xvfb')\n",
        "os.system('wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb -O ../xvfb')\n",
        "os.system('apt-get install -y python-opengl ffmpeg')\n",
        "os.system('pip install pyglet==1.2.4')\n",
        "\n",
        "# launch XVFB if you run on a server\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqOHUMZUzTa7",
        "colab_type": "text"
      },
      "source": [
        "###TRPO:Trust Region Policy Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnRAHKtyzOU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVkWRxkUzfyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f5fcab61-710c-430a-c25f-4466c39acb8e"
      },
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"Acrobot-v1\")\n",
        "env.reset()\n",
        "observation_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Action Space\", env.action_space)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space Box(6,)\n",
            "Action Space Discrete(3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ZkWW62zj1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "60ba92ad-a025-4eb8-bb87-698d224d9329"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(env.render('rgb_array'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa371de93c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuCgAruT0U2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class TRPOAgent(nn.Module):\n",
        "    def __init__(self, state_shape, n_actions, hidden_size=32):\n",
        "        '''\n",
        "        Here you should define your model\n",
        "        You should have LOG-PROBABILITIES as output because you will need it to compute loss\n",
        "        We recommend that you start simple: \n",
        "        use 1-2 hidden layers with 100-500 units and relu for the first try\n",
        "        '''\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        #<your network here >\n",
        "        self.layer1 = nn.Linear(state_shape[0], 300)\n",
        "        self.layer2 = nn.Linear(300, n_actions)\n",
        "        #self.model = torch.log(nn.Sequential(self.layer1, nn.ReLU(),self.layer2))\n",
        "\n",
        "    def forward(self, states):\n",
        "        \"\"\"\n",
        "        takes agent's observation (Variable), returns log-probabilities (Variable)\n",
        "        :param state_t: a batch of states, shape = [batch_size, state_shape]\n",
        "        \"\"\"\n",
        "\n",
        "        # Use your network to compute log_probs for given state\n",
        "        \n",
        "        log_probs = torch.log(F.softmax(self.layer2(F.relu(self.layer1(states)))))\n",
        "        return log_probs\n",
        "\n",
        "    def get_log_probs(self, states):\n",
        "        '''\n",
        "        Log-probs for training\n",
        "        '''\n",
        "\n",
        "        return self.forward(states)\n",
        "\n",
        "    def get_probs(self, states):\n",
        "        '''\n",
        "        Probs for interaction\n",
        "        '''\n",
        "\n",
        "        return torch.exp(self.forward(states))\n",
        "\n",
        "    def act(self, obs, sample=True):\n",
        "        '''\n",
        "        Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "        :param: obs - single observation vector\n",
        "        :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "        :returns: action (single integer) and probabilities for all actions\n",
        "        '''\n",
        "\n",
        "        probs = self.get_probs(Variable(torch.FloatTensor([obs]))).data.numpy()\n",
        "\n",
        "        if sample:\n",
        "            action = int(np.random.choice(n_actions, p=probs[0]))\n",
        "        else:\n",
        "            action = int(np.argmax(probs))\n",
        "\n",
        "        return action, probs[0]\n",
        "\n",
        "\n",
        "agent = TRPOAgent(observation_shape, n_actions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thTVQ_OO3-wW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73d6eb73-c06c-487c-d18d-03d1adfb34a4"
      },
      "source": [
        "observation_shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fbe0pwK0VYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "53f1d3f5-720c-489b-8b2e-829f44bae97d"
      },
      "source": [
        "# Check if log-probabilities satisfies all the requirements\n",
        "log_probs = agent.get_log_probs(Variable(torch.FloatTensor([env.reset()])))\n",
        "assert isinstance(\n",
        "    log_probs, Variable) and log_probs.requires_grad, \"qvalues must be a torch variable with grad\"\n",
        "assert len(\n",
        "    log_probs.shape) == 2 and log_probs.shape[0] == 1 and log_probs.shape[1] == n_actions\n",
        "sums = torch.sum(torch.exp(log_probs), dim=1)\n",
        "assert (0.999 < sums).all() and (1.001 > sums).all()\n",
        "\n",
        "# Demo use\n",
        "print(\"sampled:\", [agent.act(env.reset()) for _ in range(5)])\n",
        "print(\"greedy:\", [agent.act(env.reset(), sample=False) for _ in range(5)])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sampled: [(0, array([0.30442736, 0.37006506, 0.32550758], dtype=float32)), (1, array([0.30849797, 0.36672613, 0.3247759 ], dtype=float32)), (2, array([0.31483662, 0.368664  , 0.31649935], dtype=float32)), (1, array([0.310031  , 0.3714923 , 0.31847668], dtype=float32)), (2, array([0.31357569, 0.3681808 , 0.31824353], dtype=float32))]\n",
            "greedy: [(1, array([0.30903867, 0.37120444, 0.3197569 ], dtype=float32)), (1, array([0.313145  , 0.37245432, 0.31440073], dtype=float32)), (1, array([0.31278303, 0.37246954, 0.31474733], dtype=float32)), (1, array([0.31253353, 0.365006  , 0.3224605 ], dtype=float32)), (1, array([0.3127772 , 0.37251613, 0.31470668], dtype=float32))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFMe6bFh7k37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE04Rd0p6o-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtmkOEM8EUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}