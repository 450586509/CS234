{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_rl_nlp.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/450586509/reinforcement-learning-practice/blob/master/08_rl_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIozrkGuKISN",
        "colab_type": "text"
      },
      "source": [
        "### 名字生成\n",
        "\n",
        "利用rnn生成变量名，或者人名"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J9rN2MCR31q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMmCzHyDD_j3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEppykoK4NW",
        "colab_type": "text"
      },
      "source": [
        "训练数据：\n",
        "8k个拉丁文名字的训练数据。这种起名方法可以用到其它类似的场景，比如标题生成；游戏名称。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3mSv_aJKHgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "start_token = \" \"\n",
        "# 数据来源于：https://github.com/yandexdataschool/Practical_RL/tree/master/week07_%5Brecap%5D_rnn/names\n",
        "with open(\"names.txt\") as f:\n",
        "    lines = f.read()[:-1].split('\\n')\n",
        "    lines = [start_token + name for name in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jPN5oJvPgaV",
        "colab_type": "code",
        "outputId": "7592ab78-a1cc-4163-b452-35a85b1fe6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines[-3:-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Rahul', ' Shumeet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcyQjf6HMkiE",
        "colab_type": "code",
        "outputId": "9207edae-5aa2-4d9e-bd37-7cb063efe82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "\n",
        "MAX_LENGTH = max(map(len, lines))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, lines)), bins=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length = 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.900e+01, 2.720e+02, 0.000e+00, 9.260e+02, 0.000e+00, 1.878e+03,\n",
              "        0.000e+00, 2.049e+03, 0.000e+00, 1.447e+03, 0.000e+00, 8.460e+02,\n",
              "        0.000e+00, 3.510e+02, 0.000e+00, 1.160e+02, 0.000e+00, 2.400e+01,\n",
              "        0.000e+00, 1.000e+01, 0.000e+00, 3.000e+00, 0.000e+00, 1.000e+00,\n",
              "        2.000e+00]),\n",
              " array([ 3.  ,  3.52,  4.04,  4.56,  5.08,  5.6 ,  6.12,  6.64,  7.16,\n",
              "         7.68,  8.2 ,  8.72,  9.24,  9.76, 10.28, 10.8 , 11.32, 11.84,\n",
              "        12.36, 12.88, 13.4 , 13.92, 14.44, 14.96, 15.48, 16.  ]),\n",
              " <a list of 25 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrFkLF6FMnD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L15yyRzFPHnl",
        "colab_type": "text"
      },
      "source": [
        "### 文本预处理\n",
        "生成字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM1raQStN2ph",
        "colab_type": "code",
        "outputId": "9d1cdca1-5daf-4c5b-bf0b-029aa0e3dee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens = set()\n",
        "tokens.update(\"\".join(lines))\n",
        "\n",
        "tokens = list(tokens)\n",
        "\n",
        "n_tokens = len(tokens)\n",
        "print('n_tokens = ', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens =  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eQKvjlyT43X",
        "colab_type": "code",
        "outputId": "ea2d8084-4007-4594-c04e-626c30608428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_to_id = dict([(v,i) for i,v in enumerate(tokens)])\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCHQb1_NT-RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[' '], dtype='int32'):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEMQzBZKYr1w",
        "colab_type": "text"
      },
      "source": [
        "### 够着rnn图\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSTuyaUDUdlK",
        "colab_type": "code",
        "outputId": "1dbbea8b-fed8-4842-a83f-afacc1765845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as L\n",
        "%tensorflow_version 1.x\n",
        "emb_size, rnn_size = 100, 256\n",
        "\n",
        "input_sequence = tf.placeholder('int32', (None, MAX_LENGTH))\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "h0 = tf.zeros([batch_size, rnn_size])\n",
        "\n",
        "#embedding 层\n",
        "embed_x = L.Embedding(n_tokens, emb_size)\n",
        "\n",
        "# 全连接层，将当前步的input和上一个hidden state,转换为下一个hidden state\n",
        "get_h_next = L.Dense(rnn_size, activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = L.Dense(n_tokens)\n",
        "\n",
        "def rnn_one_step(x_t, h_t):\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    input_h = tf.concat([x_t_emb, h_t], axis=-1)\n",
        "    next_h = get_h_next(input_h)\n",
        "    next_probas = get_probas(next_h)\n",
        "    return next_h, next_probas\n",
        "\n",
        "prev_h = h0\n",
        "predicted_probas = []\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]\n",
        "\n",
        "    # 计算h_next和next_token。\n",
        "    next_h, next_probas = rnn_one_step(x_t, prev_h)\n",
        "    predicted_probas.append(next_probas)\n",
        "    prev_h = next_h\n",
        "\n",
        "predicted_probas = tf.stack(predicted_probas, axis=1)\n",
        "predictions_matrix = predicted_probas[:, :-1]\n",
        "\n",
        "assert predicted_probas.shape.as_list() == [None, MAX_LENGTH, n_tokens]\n",
        "assert prev_h.shape.as_list() == h0.shape.as_list()\n",
        "# label\n",
        "answers_matrix = tf.one_hot(input_sequence[:, 1:], n_tokens)\n",
        "\n",
        "print('predictions_matrix:', predictions_matrix.shape)\n",
        "print('answers_matrix:', predictions_matrix.shape)\n",
        "loss_step = tf.nn.softmax_cross_entropy_with_logits(logits=predictions_matrix, labels=answers_matrix)\n",
        "loss = tf.reduce_mean(loss_step)\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predictions_matrix: (?, 15, 55)\n",
            "answers_matrix: (?, 15, 55)\n",
            "WARNING:tensorflow:From <ipython-input-12-9a5154f8a07d>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea38zx0sbmOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST: single rnn step\n",
        "h1, p_y1 = rnn_one_step(input_sequence[:, 0], h0)\n",
        "\n",
        "dummy_data = np.arange(MAX_LENGTH * 2).reshape([2, -1])\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "test_h1, test_p_y1 = sess.run([h1, p_y1],  {input_sequence: dummy_data})\n",
        "\n",
        "assert test_h1.shape == (len(dummy_data), rnn_size)\n",
        "#assert test_p_y1.shape == (\n",
        "#    len(dummy_data), n_tokens) and np.allclose(test_p_y1.sum(-1), 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fg--dxZuaxf",
        "colab_type": "text"
      },
      "source": [
        "训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXv5WcB7uXFi",
        "colab_type": "code",
        "outputId": "e87fad14-a22b-478b-b932-e2e89a4bbdc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "sess.run(tf.global_variables_initializer())\n",
        "#lines = lines[0:1]\n",
        "history = []\n",
        "print(\"MAX_LENGTH={0}\".format(MAX_LENGTH))\n",
        "epoch_num = 50000\n",
        "batch_size = 64\n",
        "for i in range(epoch_num):\n",
        "    batch = to_matrix(sample(lines, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = sess.run([loss, optimize], {input_sequence: batch}) \n",
        "    if (i+1) % 500 == 0:\n",
        "      history.append(loss_i)\n",
        "      clear_output(True)\n",
        "      plt.plot(history, label='loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6d7PtJAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37s7LJ2NxkBV",
        "colab_type": "code",
        "outputId": "b6228ebc-5c12-46b5-f2fd-2493ba24ee77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "history[-10:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6362156,\n",
              " 0.62365985,\n",
              " 0.6169111,\n",
              " 0.62844646,\n",
              " 0.61816794,\n",
              " 0.62153995,\n",
              " 0.6324198,\n",
              " 0.61776155,\n",
              " 0.6227567,\n",
              " 0.6219831]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFnKOHwJXl6W",
        "colab_type": "code",
        "outputId": "190a11b7-48c3-43dd-ccae-924bbfd02aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id_to_token = dict([(v, k) for k, v in token_to_id.items()])\n",
        "\n",
        "print(\"\".join([id_to_token[i] for i in batch[0]]))\n",
        "loss_step\n",
        "lt, pm, am = sess.run([loss_step,predictions_matrix,answers_matrix],{input_sequence: batch})\n",
        "#print(\"loss_step={}\".format(lt))\n",
        "#print(\"prediction={}\".format(pm[0][0]))\n",
        "#print(\"label={}\".format(am[0][0]))\n",
        "#v= tf.nn.softmax(np.array(am[0][0]))\n",
        "#print(v.eval())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Minni          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXiK2fx284NT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0) # only difference\n",
        "\n",
        "x_t = tf.placeholder('int32', (None,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_size], 'float32'))\n",
        "\n",
        "next_h, next_probs = rnn_one_step(x_t, h_t)\n",
        "\n",
        "def generate_sample(seed_phrase=' ', max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    sess.run(tf.variables_initializer([h_t]))\n",
        "\n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "        sess.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "\n",
        "    # start generating \n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs, _ = sess.run([next_probs, tf.assign(h_t, next_h)], {\n",
        "                              x_t: [x_sequence[-1]]})\n",
        "        \n",
        "        #print(\"x_probs={0}\".format(x_probs))\n",
        "        x_probs = tf.nn.softmax(x_probs).eval()\n",
        "        #x_probs = tf.nn.sofmax()\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        #print(\"x_sequence={0}\".format(x_sequence))\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_azBVFXMMRpJ",
        "colab_type": "code",
        "outputId": "ad7442ad-05d7-4a41-9a4a-f951f57061ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "id_to_token = dict([(v, k) for k, v in token_to_id.items()])\n",
        "for _ in range(1):\n",
        "    print(generate_sample(\" Zab\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Zabrina        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9BKyZTQ2oH5",
        "colab_type": "code",
        "outputId": "113c1854-a57d-4dfb-dd62-289d928f8cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "line_filter = filter(lambda x: x.startswith(\" Za\"), lines)\n",
        "print(list(line_filter))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Zabrina', ' Zahara', ' Zandra', ' Zaneta', ' Zara', ' Zarah', ' Zaria', ' Zarla', ' Zach', ' Zacharia', ' Zachariah', ' Zacharias', ' Zacharie', ' Zachary', ' Zacherie', ' Zachery', ' Zack', ' Zackariah', ' Zak', ' Zalman', ' Zane', ' Zared', ' Zary']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57WAZEE1hHCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzClNTbnTekS",
        "colab_type": "text"
      },
      "source": [
        "### 每个bathc中使用不定长的序列长度\n",
        "测试不同类型的cell。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_zVupiSjJMa",
        "colab_type": "code",
        "outputId": "c9a100ca-dee7-4d56-8849-d33f810bed93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m52IuQr-A2ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(object):\n",
        "    def __init__(self, samples, token2id):\n",
        "        self.data = samples\n",
        "        self.data_size = len(samples)\n",
        "        self.token2id = token2id\n",
        "\n",
        "    def batch_generator(self, epoch, batch_size):\n",
        "        num = (self.data_size // batch_size) + 1\n",
        "        print(\"batch per epoch={0}\".format(num))\n",
        "        step = 0\n",
        "        for j in range(epoch):\n",
        "            print(\"epoch={0}\".format(j))\n",
        "            for i in range(num):\n",
        "                start = i * batch_size\n",
        "                end = (i + 1) * batch_size\n",
        "                batch_data = self.data[start:end]\n",
        "\n",
        "                if len(batch_data) > 0:\n",
        "                    x, y = self.transform(batch_data)\n",
        "                    yield x, y, step, j\n",
        "                step = step + 1\n",
        "            # shuffle\n",
        "            # self.shuffle()\n",
        "\n",
        "    def shuffle(self):\n",
        "        perm = np.arange(self.data_size)\n",
        "        numpy.random.shuffle(perm)\n",
        "        self.data = self.data[perm]\n",
        "    def transform(self, lines):\n",
        "      \n",
        "      lines_ch = map(lambda x: list(x), lines)\n",
        "      #padding。\n",
        "      max_size = max(map(lambda x : len(x), lines))\n",
        "      lines_ch = list(map(lambda x: x + [\"#\" for i in range(max_size - len(x))], lines_ch))\n",
        "      #to num\n",
        "      lines_num = [[self.token2id[ch] for ch in line_ch]for line_ch in lines_ch]\n",
        "      lines_num = np.array(lines_num)\n",
        "      lines_ch_x = lines_num[:,:-1]\n",
        "      lines_ch_y = lines_num[:,1:]\n",
        "      return lines_ch_x, lines_ch_y\n",
        "\n",
        "\n",
        "with open(\"./names\") as f:\n",
        "    lines = f.read()[:-1].split('\\n')\n",
        "    #lines = [start_token + name for name in lines]\n",
        "\n",
        "lines_ch = list(map(lambda line: list(line), lines))\n",
        "lines_ch = list(map(lambda x: ['start']+x+['end'], lines_ch))\n",
        "from collections import Counter\n",
        "count = Counter()\n",
        "for ls in lines_ch:\n",
        "  count.update(ls)\n",
        "token2id={}\n",
        "for i,(k, v) in enumerate(count.most_common()):\n",
        "  token2id[k] = i\n",
        "\n",
        "token2id['#'] = len(token2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se_oapcnD20q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhFnh42yEBpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkzezgXpjNA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 配置\n",
        "emb_size, rnn_size = 100, 256\n",
        "batch_size = 32\n",
        "n_tokens = len(token2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QuyHp9-Tk5F",
        "colab_type": "code",
        "outputId": "b0b5652c-b966-4293-bedb-6f9c5e67fb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "  def call(self, input, state):\n",
        "    input_h = tf.concat([input, state], axis=-1)\n",
        "    next_h = get_h_next(input_h)\n",
        "    return next_h, next_h\n",
        "\n",
        "  @property\n",
        "  def output_size(self):\n",
        "      return rnn_size\n",
        "\n",
        "#embedding 层\n",
        "embed_x = L.Embedding(n_tokens, emb_size)\n",
        "# 全连接层，将当前步的input和上一个hidden state,转换为下一个hidden state\n",
        "get_h_next = L.Dense(rnn_size, activation='tanh')\n",
        "# rnn的输出层。\n",
        "get_probas = L.Dense(n_tokens)\n",
        "\n",
        "x_ph = tf.placeholder(dtype=tf.float32,shape=(None, None),name=\"x_ph\")\n",
        "label_ph = tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"label_ph\")\n",
        "x_embed = embed_x(x_ph)\n",
        "cell = CustomRNN(rnn_size)\n",
        "print(\"====================================\")\n",
        "print(\"x_ph.shape={}\".format(x_ph))\n",
        "print(\"x_embed.shape={}\".format(x_embed))\n",
        "\n",
        "\n",
        "#todo: time_major和dtype的作用\n",
        "#time_major的值决定了input和output的每个维度的含义。time_major=False时， inputs 和outputs 张量的形状格式为：[batch_size, max_time, input_size]。\n",
        "#time_major=True时，inputs 和outputs 张量的形状格式为：[max_time, batch_size, input_size]\n",
        "step_states, last_state = tf.nn.dynamic_rnn(cell, x_embed, time_major=False, dtype='float32')\n",
        "print(\"step_states shape={}\".format(step_states.shape))\n",
        "print(\"last shape={}\".format(last_state.shape))\n",
        "predicted_probas = get_probas(step_states)\n",
        "\n",
        "#todo predicted_probas每一个维度的含义。[batch_size, max_step_num, cell.output_size]\n",
        "print(\"predicted_probas={}\".format(predicted_probas.shape))\n",
        "answers_matrix = tf.one_hot(label_ph, n_tokens)\n",
        "\n",
        "loss_step = tf.nn.softmax_cross_entropy_with_logits(logits=predicted_probas, labels=answers_matrix)\n",
        "loss = tf.reduce_mean(loss_step)\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From <ipython-input-6-6449eac6f00f>:21: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "====================================\n",
            "x_ph.shape=Tensor(\"x_ph:0\", shape=(?, ?), dtype=float32)\n",
            "x_embed.shape=Tensor(\"embedding/embedding_lookup/Identity_1:0\", shape=(?, ?, 100), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-6-6449eac6f00f>:30: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "step_states shape=(?, ?, 256)\n",
            "last shape=(?, 256)\n",
            "predicted_probas=(?, ?, 58)\n",
            "WARNING:tensorflow:From <ipython-input-6-6449eac6f00f>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1R22UIjWiyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6sAfh3cmgrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiCI9TdI8w7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gene = DataGenerator(samples=lines_ch, token2id=token2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq0HpmJ_92yN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35ad2ee8-f8eb-49d9-fbb8-cb8723326f0a"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "train_loss=[]\n",
        "index = 0\n",
        "for batch_x, batch_y,_,_ in data_gene.batch_generator(epoch=20, batch_size=64):\n",
        "  \n",
        "  while True:\n",
        "    index = index + 1\n",
        "    loss_val,_ = sess.run([loss, optimize], feed_dict={x_ph:batch_x, label_ph:batch_y})\n",
        "    if index%50 ==0:\n",
        "      print(\"loss_val={0}\".format(loss_val))\n",
        "  #if index % 10 == 0:\n",
        "  #  train_loss.append(loss_val)\n",
        "  #  clear_output(True)\n",
        "  #  plt.plot(train_loss, label='loss')\n",
        "  #  plt.legend()\n",
        "  #  plt.show()\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch per epoch=125\n",
            "epoch=0\n",
            "loss_val=0.46593889594078064\n",
            "loss_val=0.465619295835495\n",
            "loss_val=0.46533939242362976\n",
            "loss_val=0.46509265899658203\n",
            "loss_val=0.46487364172935486\n",
            "loss_val=0.46467822790145874\n",
            "loss_val=0.4645030200481415\n",
            "loss_val=0.46434512734413147\n",
            "loss_val=0.4642024636268616\n",
            "loss_val=0.46407270431518555\n",
            "loss_val=0.46395450830459595\n",
            "loss_val=0.4638464152812958\n",
            "loss_val=0.4637472331523895\n",
            "loss_val=0.4636560082435608\n",
            "loss_val=0.4635718762874603\n",
            "loss_val=0.46349409222602844\n",
            "loss_val=0.46342214941978455\n",
            "loss_val=0.4633551239967346\n",
            "loss_val=0.4632928669452667\n",
            "loss_val=0.46323490142822266\n",
            "loss_val=0.46318066120147705\n",
            "loss_val=0.4631298780441284\n",
            "loss_val=0.46308252215385437\n",
            "loss_val=0.46303790807724\n",
            "loss_val=0.46299606561660767\n",
            "loss_val=0.46295663714408875\n",
            "loss_val=0.4629194438457489\n",
            "loss_val=0.46288448572158813\n",
            "loss_val=0.46285146474838257\n",
            "loss_val=0.46282026171684265\n",
            "loss_val=0.46279075741767883\n",
            "loss_val=0.46276262402534485\n",
            "loss_val=0.4627361297607422\n",
            "loss_val=0.4627109169960022\n",
            "loss_val=0.46268701553344727\n",
            "loss_val=0.46266427636146545\n",
            "loss_val=0.4626426100730896\n",
            "loss_val=0.46262210607528687\n",
            "loss_val=0.4626024067401886\n",
            "loss_val=0.4625837504863739\n",
            "loss_val=0.46256595849990845\n",
            "loss_val=0.4625488817691803\n",
            "loss_val=0.4625326693058014\n",
            "loss_val=0.46251705288887024\n",
            "loss_val=0.4625021517276764\n",
            "loss_val=0.46248796582221985\n",
            "loss_val=0.46247440576553345\n",
            "loss_val=0.4624612629413605\n",
            "loss_val=0.4624488651752472\n",
            "loss_val=0.46243688464164734\n",
            "loss_val=0.4624253809452057\n",
            "loss_val=0.46241438388824463\n",
            "loss_val=0.46240371465682983\n",
            "loss_val=0.46239355206489563\n",
            "loss_val=0.462383896112442\n",
            "loss_val=0.46237441897392273\n",
            "loss_val=0.4623652696609497\n",
            "loss_val=0.46235668659210205\n",
            "loss_val=0.4623483419418335\n",
            "loss_val=0.46234020590782166\n",
            "loss_val=0.46233245730400085\n",
            "loss_val=0.46232497692108154\n",
            "loss_val=0.46231788396835327\n",
            "loss_val=0.46232667565345764\n",
            "loss_val=0.46230900287628174\n",
            "loss_val=0.4622983932495117\n",
            "loss_val=0.4622920751571655\n",
            "loss_val=0.462286114692688\n",
            "loss_val=0.4622802734375\n",
            "loss_val=0.46228620409965515\n",
            "loss_val=0.46227073669433594\n",
            "loss_val=0.4622650146484375\n",
            "loss_val=0.46225982904434204\n",
            "loss_val=0.4623275399208069\n",
            "loss_val=0.4622516632080078\n",
            "loss_val=0.4622465670108795\n",
            "loss_val=0.4622419774532318\n",
            "loss_val=0.46223750710487366\n",
            "loss_val=0.46326202154159546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-499673af1abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss_val={0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9phgRO696bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c729106e-03ed-426a-9407-17697515c382"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['s_start', 'a', 's_end', '#'],\n",
              " ['s_start', 'a', 'b', 's_end'],\n",
              " ['s_start', 'a', 'b', 'c']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4qFMbMq_pWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0f6f13b-b1e2-46e3-abb9-4c8621222762"
      },
      "source": [
        "y"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 's_end', '#', '#'], ['a', 'b', 's_end', '#'], ['a', 'b', 'c', 's_end']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEKO74hc_rM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}